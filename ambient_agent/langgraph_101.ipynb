{"cells":[{"cell_type":"markdown","id":"dc082433","metadata":{"id":"dc082433"},"source":["# LangGraph 101\n","\n","[LLMs](https://python.langchain.com/docs/concepts/chat_models/) make it possible to embed intelligence into a new class of applications. [LangGraph](https://langchain-ai.github.io/langgraph/) is a framework to help build applications with LLMs. Here, we will overview the basics of LangGraph, explain its benefits, show how to use it to build workflows / agents, and show how it works with [LangChain](https://www.langchain.com/) / [LangSmith](https://docs.smith.langchain.com/).\n","\n","![ecosystem](./img/ecosystem.png)\n","\n","## Chat models\n","\n","[Chat models](https://python.langchain.com/docs/concepts/chat_models/) are the foundation of LLM applications. They are typically accessed through a chat interface that takes a list of [messages](https://python.langchain.com/docs/concepts/messages/) as input and returns a [message](https://python.langchain.com/docs/concepts/messages/) as output. LangChain provides [a standardized interface for chat models](https://python.langchain.com/api_reference/langchain/chat_models/langchain.chat_models.base.init_chat_model.html), making it easy to [access many different providers](https://python.langchain.com/docs/integrations/chat/)."]},{"cell_type":"code","source":["### Mount Notebook to Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JWja6N2PrxX1","executionInfo":{"status":"ok","timestamp":1755831060285,"user_tz":-480,"elapsed":25334,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"e8ee24d4-c9c7-44d3-d14c-bac3a4bac93e"},"id":"JWja6N2PrxX1","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# change the working directory to the Drive root\n","%cd /content/drive/My\\ Drive/Colab\\ Notebooks/agents-from-scratch-main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m7_tc737tdBc","executionInfo":{"status":"ok","timestamp":1755834522096,"user_tz":-480,"elapsed":61,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"8cd07c9c-cff2-4fae-b3b4-0fb02929fc7e"},"id":"m7_tc737tdBc","execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Colab Notebooks/agents-from-scratch-main\n"]}]},{"cell_type":"code","source":["!pip install --quiet python-dotenv"],"metadata":{"id":"YREI9FkztcmC","executionInfo":{"status":"ok","timestamp":1755831516367,"user_tz":-480,"elapsed":8587,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}}},"id":"YREI9FkztcmC","execution_count":3,"outputs":[]},{"cell_type":"code","source":["!pip install -U \"langchain[google-genai]\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UbW9SFJArvut","executionInfo":{"status":"ok","timestamp":1755834109657,"user_tz":-480,"elapsed":9319,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"a79e8da8-e499-4bd4-d319-032d00a081e6"},"id":"UbW9SFJArvut","execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: langchain[google-genai] in /usr/local/lib/python3.12/dist-packages (0.3.27)\n","Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain[google-genai]) (0.3.74)\n","Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain[google-genai]) (0.3.9)\n","Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain[google-genai]) (0.4.14)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain[google-genai]) (2.11.7)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain[google-genai]) (2.0.43)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain[google-genai]) (2.32.4)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain[google-genai]) (6.0.2)\n","Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.12/dist-packages (from langchain[google-genai]) (2.1.9)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain[google-genai]) (8.5.0)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain[google-genai]) (1.33)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain[google-genai]) (4.14.1)\n","Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain[google-genai]) (25.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain[google-genai]) (0.28.1)\n","Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain[google-genai]) (3.11.2)\n","Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain[google-genai]) (1.0.0)\n","Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain[google-genai]) (0.24.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain[google-genai]) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain[google-genai]) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain[google-genai]) (0.4.1)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain[google-genai]) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain[google-genai]) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain[google-genai]) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain[google-genai]) (2025.8.3)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain[google-genai]) (3.2.4)\n","Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai->langchain[google-genai]) (1.2.0)\n","Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai->langchain[google-genai]) (0.6.18)\n","Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (2.25.1)\n","Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (2.38.0)\n","Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (1.26.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (5.29.5)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain[google-genai]) (4.10.0)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain[google-genai]) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain[google-genai]) (0.16.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain[google-genai]) (3.0.0)\n","Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (1.70.0)\n","Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (1.74.0)\n","Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (1.71.2)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (5.5.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (0.4.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (4.9.1)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain[google-genai]) (1.3.1)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (0.6.1)\n"]}]},{"cell_type":"code","source":["!pip install -U langgraph"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o0VvOZ3v3XiQ","executionInfo":{"status":"ok","timestamp":1755834098065,"user_tz":-480,"elapsed":6167,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"483f1216-e409-4088-b22e-b4f6728456fc"},"id":"o0VvOZ3v3XiQ","execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langgraph\n","  Downloading langgraph-0.6.6-py3-none-any.whl.metadata (6.8 kB)\n","Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.74)\n","Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n","  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n","Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n","  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n","Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n","  Downloading langgraph_sdk-0.2.3-py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.11.7)\n","Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.5.0)\n","Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.4.14)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (4.14.1)\n","Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n","Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n","  Downloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n","Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.10.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.8.3)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n","Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.10)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n","Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n","Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.32.4)\n","Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.24.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (3.4.3)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n","Downloading langgraph-0.6.6-py3-none-any.whl (153 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n","Downloading langgraph_sdk-0.2.3-py3-none-any.whl (52 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n","Successfully installed langgraph-0.6.6 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.3 ormsgpack-1.10.0\n"]}]},{"cell_type":"code","execution_count":36,"id":"cecc2b24","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cecc2b24","executionInfo":{"status":"ok","timestamp":1755834538653,"user_tz":-480,"elapsed":37,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"24a6c144-4bc2-4c5c-c306-8de54457a2f7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":36}],"source":["from dotenv import load_dotenv\n","load_dotenv(\"../.env\", override=True)"]},{"cell_type":"code","execution_count":8,"id":"e0ee8f6c","metadata":{"id":"e0ee8f6c","executionInfo":{"status":"ok","timestamp":1755831575913,"user_tz":-480,"elapsed":2181,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}}},"outputs":[],"source":["from langchain.chat_models import init_chat_model\n","#llm = init_chat_model(\"openai:gpt-4.1\", temperature=0)\n","llm = init_chat_model(\"google_genai:gemini-2.0-flash\")\n"]},{"cell_type":"markdown","id":"50777b0b","metadata":{"id":"50777b0b"},"source":["## Running the model\n","\n","The `init_chat_model` interface provides [standardized](https://python.langchain.com/docs/concepts/runnables/) methods for using chat models, which include:\n","- `invoke()`: A single input is transformed into an output.\n","- `stream()`: Outputs are [streamed](https://python.langchain.com/docs/concepts/streaming/#stream-and-astream) as they are produced."]},{"cell_type":"code","execution_count":9,"id":"a28159d5","metadata":{"id":"a28159d5","executionInfo":{"status":"ok","timestamp":1755831584134,"user_tz":-480,"elapsed":4097,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}}},"outputs":[],"source":["result = llm.invoke(\"What is an agent?\")"]},{"cell_type":"code","execution_count":10,"id":"41137023","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":186},"id":"41137023","executionInfo":{"status":"ok","timestamp":1755831587268,"user_tz":-480,"elapsed":31,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"db2fb050-da36-47c4-bb77-c859d1338e9e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["langchain_core.messages.ai.AIMessage"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>langchain_core.messages.ai.AIMessage</b><br/>def __init__(content: Union[str, list[Union[str, dict]]], **kwargs: Any) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/langchain_core/messages/ai.py</a>Message from an AI.\n","\n","AIMessage is returned from a chat model as a response to a prompt.\n","\n","This message represents the output of the model and consists of both\n","the raw output as returned by the model together standardized fields\n","(e.g., tool calls, usage metadata) added by the LangChain framework.</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 154);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{},"execution_count":10}],"source":["type(result)"]},{"cell_type":"code","execution_count":11,"id":"dc1d00eb","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":865},"id":"dc1d00eb","executionInfo":{"status":"ok","timestamp":1755831592820,"user_tz":-480,"elapsed":174,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"2213d001-13f1-4deb-abd5-35afa1f28c6d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["The term \"agent\" is used in a variety of fields, but the core concept remains the same: \u001b[1man agent is an entity that \u001b[0m\n","\u001b[1mcan perceive its environment and act upon it to achieve a specific goal.\u001b[0m                                           \n","\n","Here's a breakdown of what that means and how it applies in different contexts:                                    \n","\n","\u001b[1mCore Components of an Agent:\u001b[0m                                                                                       \n","\n","\u001b[1;33m • \u001b[0m\u001b[1mPerception:\u001b[0m The ability to sense or gather information about the environment. This can involve sensors (in the  \n","\u001b[1;33m   \u001b[0mcase of physical agents) or data input (in the case of software agents).                                        \n","\u001b[1;33m • \u001b[0m\u001b[1mEnvironment:\u001b[0m The surroundings that the agent exists within and interacts with.                                  \n","\u001b[1;33m • \u001b[0m\u001b[1mAction:\u001b[0m The capability to perform actions that affect the environment.  This can be physical movement, data     \n","\u001b[1;33m   \u001b[0mmanipulation, communication, or any other change that the agent can initiate.                                   \n","\u001b[1;33m • \u001b[0m\u001b[1mGoal:\u001b[0m  A specific objective or set of objectives that the agent is trying to achieve.                           \n","\u001b[1;33m • \u001b[0m\u001b[1mDecision-Making:\u001b[0m The logic or algorithm that the agent uses to determine which action to take based on its      \n","\u001b[1;33m   \u001b[0mperception, current state, and goal.                                                                            \n","\n","\u001b[1mExamples of Agents in Different Fields:\u001b[0m                                                                            \n","\n","\u001b[1;33m • \u001b[0m\u001b[1mArtificial Intelligence (AI):\u001b[0m                                                                                   \n","\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mSoftware Agents:\u001b[0m Programs designed to automate tasks, gather information, or interact with users. Examples   \n","\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0minclude:                                                                                                     \n","\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mSearch engine bots (crawlers)                                                                             \n","\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mChatbots                                                                                                  \n","\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mPersonal assistants (Siri, Alexa)                                                                         \n","\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mRecommendation systems                                                                                    \n","\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mTrading bots                                                                                              \n","\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mRobotics:\u001b[0m Physical robots that can perceive their environment through sensors (cameras, lidar, etc.) and act \n","\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0mupon it using motors, actuators, etc. Examples include:                                                      \n","\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mIndustrial robots                                                                                         \n","\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mAutonomous vehicles                                                                                       \n","\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mService robots (cleaning robots, delivery robots)                                                         \n","\u001b[1;33m • \u001b[0m\u001b[1mEconomics:\u001b[0m                                                                                                      \n","\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mEconomic Agents:\u001b[0m Individuals, firms, or governments that make decisions that affect the economy. They        \n","\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0mperceive economic signals (prices, interest rates, etc.) and act to maximize their own utility or profit.    \n","\u001b[1;33m • \u001b[0m\u001b[1mGame Theory:\u001b[0m                                                                                                    \n","\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mPlayers:\u001b[0m  Individuals or entities that make choices in a strategic setting, with the goal of maximizing their\n","\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0mown payoff.                                                                                                  \n","\u001b[1;33m • \u001b[0m\u001b[1mMulti-Agent Systems (MAS):\u001b[0m Systems composed of multiple agents that interact with each other to achieve a common\n","\u001b[1;33m   \u001b[0mgoal or individual goals in a shared environment.  These agents may cooperate, compete, or coordinate their     \n","\u001b[1;33m   \u001b[0mactions.                                                                                                        \n","\n","\u001b[1mKey Characteristics of Agents:\u001b[0m                                                                                     \n","\n","\u001b[1;33m • \u001b[0m\u001b[1mAutonomy:\u001b[0m  Agents can operate without direct human intervention. They can make decisions and take actions on    \n","\u001b[1;33m   \u001b[0mtheir own.                                                                                                      \n","\u001b[1;33m • \u001b[0m\u001b[1mReactivity:\u001b[0m Agents can perceive changes in their environment and respond to them in a timely manner.            \n","\u001b[1;33m • \u001b[0m\u001b[1mProactiveness:\u001b[0m Agents can take initiative and pursue goals even in the absence of immediate stimuli.            \n","\u001b[1;33m • \u001b[0m\u001b[1mSocial Ability (for multi-agent systems):\u001b[0m Agents can communicate and interact with other agents.                \n","\u001b[1;33m • \u001b[0m\u001b[1mAdaptability/Learning:\u001b[0m Agents can improve their performance over time by learning from their experiences.       \n","\n","\u001b[1mIn summary, an agent is an entity capable of perceiving its environment, making decisions, and acting upon that \u001b[0m   \n","\u001b[1menvironment to achieve a goal.  The specific implementation and complexity of an agent can vary greatly depending \u001b[0m \n","\u001b[1mon the domain and the task it is designed to perform.\u001b[0m                                                              \n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The term \"agent\" is used in a variety of fields, but the core concept remains the same: <span style=\"font-weight: bold\">an agent is an entity that </span>\n","<span style=\"font-weight: bold\">can perceive its environment and act upon it to achieve a specific goal.</span>                                           \n","\n","Here's a breakdown of what that means and how it applies in different contexts:                                    \n","\n","<span style=\"font-weight: bold\">Core Components of an Agent:</span>                                                                                       \n","\n","<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Perception:</span> The ability to sense or gather information about the environment. This can involve sensors (in the  \n","<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>case of physical agents) or data input (in the case of software agents).                                        \n","<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Environment:</span> The surroundings that the agent exists within and interacts with.                                  \n","<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Action:</span> The capability to perform actions that affect the environment.  This can be physical movement, data     \n","<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>manipulation, communication, or any other change that the agent can initiate.                                   \n","<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Goal:</span>  A specific objective or set of objectives that the agent is trying to achieve.                           \n","<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Decision-Making:</span> The logic or algorithm that the agent uses to determine which action to take based on its      \n","<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>perception, current state, and goal.                                                                            \n","\n","<span style=\"font-weight: bold\">Examples of Agents in Different Fields:</span>                                                                            \n","\n","<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Artificial Intelligence (AI):</span>                                                                                   \n","<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">Software Agents:</span> Programs designed to automate tasks, gather information, or interact with users. Examples   \n","<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span>include:                                                                                                     \n","<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">       • </span>Search engine bots (crawlers)                                                                             \n","<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">       • </span>Chatbots                                                                                                  \n","<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">       • </span>Personal assistants (Siri, Alexa)                                                                         \n","<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">       • </span>Recommendation systems                                                                                    \n","<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">       • </span>Trading bots                                                                                              \n","<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">Robotics:</span> Physical robots that can perceive their environment through sensors (cameras, lidar, etc.) and act \n","<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span>upon it using motors, actuators, etc. Examples include:                                                      \n","<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">       • </span>Industrial robots                                                                                         \n","<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">       • </span>Autonomous vehicles                                                                                       \n","<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">       • </span>Service robots (cleaning robots, delivery robots)                                                         \n","<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Economics:</span>                                                                                                      \n","<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">Economic Agents:</span> Individuals, firms, or governments that make decisions that affect the economy. They        \n","<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span>perceive economic signals (prices, interest rates, etc.) and act to maximize their own utility or profit.    \n","<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Game Theory:</span>                                                                                                    \n","<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">Players:</span>  Individuals or entities that make choices in a strategic setting, with the goal of maximizing their\n","<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span>own payoff.                                                                                                  \n","<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Multi-Agent Systems (MAS):</span> Systems composed of multiple agents that interact with each other to achieve a common\n","<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>goal or individual goals in a shared environment.  These agents may cooperate, compete, or coordinate their     \n","<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>actions.                                                                                                        \n","\n","<span style=\"font-weight: bold\">Key Characteristics of Agents:</span>                                                                                     \n","\n","<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Autonomy:</span>  Agents can operate without direct human intervention. They can make decisions and take actions on    \n","<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>their own.                                                                                                      \n","<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Reactivity:</span> Agents can perceive changes in their environment and respond to them in a timely manner.            \n","<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Proactiveness:</span> Agents can take initiative and pursue goals even in the absence of immediate stimuli.            \n","<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Social Ability (for multi-agent systems):</span> Agents can communicate and interact with other agents.                \n","<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Adaptability/Learning:</span> Agents can improve their performance over time by learning from their experiences.       \n","\n","<span style=\"font-weight: bold\">In summary, an agent is an entity capable of perceiving its environment, making decisions, and acting upon that </span>   \n","<span style=\"font-weight: bold\">environment to achieve a goal.  The specific implementation and complexity of an agent can vary greatly depending </span> \n","<span style=\"font-weight: bold\">on the domain and the task it is designed to perform.</span>                                                              \n","</pre>\n"]},"metadata":{},"execution_count":11}],"source":["from rich.markdown import Markdown\n","Markdown(result.content)"]},{"cell_type":"markdown","id":"9a24d8ef","metadata":{"id":"9a24d8ef"},"source":["## Tools\n","\n","[Tools](https://python.langchain.com/docs/concepts/tools/) are utilities that can be called by a chat model. In LangChain, creating tools can be done using the `@tool` decorator, which transforms Python functions into callable tools. It will automatically infer the tool's name, description, and expected arguments from the function definition. You can also use [Model Context Protocol (MCP) servers](https://github.com/langchain-ai/langchain-mcp-adapters) as LangChain-compatible tools."]},{"cell_type":"code","execution_count":12,"id":"afdff275","metadata":{"id":"afdff275","executionInfo":{"status":"ok","timestamp":1755831923637,"user_tz":-480,"elapsed":43,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}}},"outputs":[],"source":["from langchain.tools import tool\n","\n","@tool\n","def write_email(to: str, subject: str, content: str) -> str:\n","    \"\"\"Write and send an email.\"\"\"\n","    # Placeholder response - in real app would send email\n","    return f\"Email sent to {to} with subject '{subject}' and content: {content}\""]},{"cell_type":"code","execution_count":13,"id":"c52ec55b-0b60-4b0c-95d4-ff528a64694e","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":120},"id":"c52ec55b-0b60-4b0c-95d4-ff528a64694e","executionInfo":{"status":"ok","timestamp":1755831927998,"user_tz":-480,"elapsed":47,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"582f2120-e498-4649-d02f-bf297a9552b6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["langchain_core.tools.structured.StructuredTool"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>langchain_core.tools.structured.StructuredTool</b><br/>def warning_emitting_wrapper(*args: Any, **kwargs: Any) -&gt; Any</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/langchain_core/tools/structured.py</a>Tool that can operate on any number of inputs.</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 39);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{},"execution_count":13}],"source":["type(write_email)"]},{"cell_type":"code","execution_count":14,"id":"23a40647-3d48-4760-aabe-144d627de110","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"23a40647-3d48-4760-aabe-144d627de110","executionInfo":{"status":"ok","timestamp":1755831952288,"user_tz":-480,"elapsed":13,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"6de7f185-dd77-434c-cae9-b6ee95e3df58"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'to': {'title': 'To', 'type': 'string'},\n"," 'subject': {'title': 'Subject', 'type': 'string'},\n"," 'content': {'title': 'Content', 'type': 'string'}}"]},"metadata":{},"execution_count":14}],"source":["write_email.args"]},{"cell_type":"code","execution_count":15,"id":"abd85ae4-9d4c-4efa-9577-aca96e9f22cd","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":33},"id":"abd85ae4-9d4c-4efa-9577-aca96e9f22cd","executionInfo":{"status":"ok","timestamp":1755831956551,"user_tz":-480,"elapsed":27,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"e682e1f9-cedd-47d2-9fbe-908bdeb5a9b7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Write and send an email.                                                                                           \n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Write and send an email.                                                                                           \n","</pre>\n"]},"metadata":{},"execution_count":15}],"source":["Markdown(write_email.description)"]},{"cell_type":"markdown","id":"c8a6b427","metadata":{"id":"c8a6b427"},"source":["## Tool Calling\n","\n","Tools can be [called](https://python.langchain.com/docs/concepts/tool_calling/) by LLMs. When a tool is bound to the model, the model can choose to call the tool by returning a structured output with tool arguments. We use the `bind_tools` method to augment an LLM with tools.\n","\n","![tool-img](img/tool_call_detail.png)\n","\n","Providers often have [parameters such as `tool_choice`](https://python.langchain.com/docs/how_to/tool_choice/) to enforce calling specific tools. `any` will select at least one of the tools.\n","\n","In addition, we can [set `parallel_tool_calls=False`](https://python.langchain.com/docs/how_to/tool_calling_parallel/) to ensure the model will only call one tool at a time."]},{"cell_type":"code","execution_count":16,"id":"bfa57bc4","metadata":{"id":"bfa57bc4","executionInfo":{"status":"ok","timestamp":1755832140962,"user_tz":-480,"elapsed":797,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}}},"outputs":[],"source":["# Connect tools to a chat model\n","model_with_tools = llm.bind_tools([write_email], tool_choice=\"any\", parallel_tool_calls=False)\n","\n","# The model will now be able to call tools\n","output = model_with_tools.invoke(\"Draft a response to my boss (boss@company.ai) about tomorrow's meeting\")"]},{"cell_type":"code","execution_count":17,"id":"7985eab6-9e6b-4fa5-8027-52d32886b97e","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":186},"id":"7985eab6-9e6b-4fa5-8027-52d32886b97e","executionInfo":{"status":"ok","timestamp":1755832143954,"user_tz":-480,"elapsed":214,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"1a249f26-169a-4181-d6c4-82bcc6b38a8a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["langchain_core.messages.ai.AIMessage"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>langchain_core.messages.ai.AIMessage</b><br/>def __init__(content: Union[str, list[Union[str, dict]]], **kwargs: Any) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/langchain_core/messages/ai.py</a>Message from an AI.\n","\n","AIMessage is returned from a chat model as a response to a prompt.\n","\n","This message represents the output of the model and consists of both\n","the raw output as returned by the model together standardized fields\n","(e.g., tool calls, usage metadata) added by the LangChain framework.</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 154);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{},"execution_count":17}],"source":["type(output)"]},{"cell_type":"code","execution_count":18,"id":"ea0ce030-e760-4679-838f-d88d1480664e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ea0ce030-e760-4679-838f-d88d1480664e","executionInfo":{"status":"ok","timestamp":1755832147598,"user_tz":-480,"elapsed":47,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"b6ef01a9-b854-4664-e24f-f353bc68c46b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content='', additional_kwargs={'function_call': {'name': 'write_email', 'arguments': '{\"to\": \"boss@company.ai\", \"content\": \"Hi Boss,\\\\n\\\\nI\\'m writing to confirm our meeting tomorrow. I\\'m looking forward to it.\\\\n\\\\nBest,\\\\n[Your Name]\", \"subject\": \"Regarding tomorrow\\'s meeting\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--8d2b537d-cdb7-4e37-8196-30a5c73b6a36-0', tool_calls=[{'name': 'write_email', 'args': {'to': 'boss@company.ai', 'content': \"Hi Boss,\\n\\nI'm writing to confirm our meeting tomorrow. I'm looking forward to it.\\n\\nBest,\\n[Your Name]\", 'subject': \"Regarding tomorrow's meeting\"}, 'id': '0bfe0ea0-a6ad-4d1f-823a-9a00576dd521', 'type': 'tool_call'}], usage_metadata={'input_tokens': 37, 'output_tokens': 46, 'total_tokens': 83, 'input_token_details': {'cache_read': 0}})"]},"metadata":{},"execution_count":18}],"source":["output"]},{"cell_type":"code","execution_count":19,"id":"717779cb","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"717779cb","executionInfo":{"status":"ok","timestamp":1755832151611,"user_tz":-480,"elapsed":31,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"34fa0b32-64f1-4da1-a822-bf6694d5bdc0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'to': 'boss@company.ai',\n"," 'content': \"Hi Boss,\\n\\nI'm writing to confirm our meeting tomorrow. I'm looking forward to it.\\n\\nBest,\\n[Your Name]\",\n"," 'subject': \"Regarding tomorrow's meeting\"}"]},"metadata":{},"execution_count":19}],"source":["# Extract tool calls and execute them\n","args = output.tool_calls[0]['args']\n","args"]},{"cell_type":"code","execution_count":20,"id":"09f85694","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":97},"id":"09f85694","executionInfo":{"status":"ok","timestamp":1755832155661,"user_tz":-480,"elapsed":36,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"a5e06402-8cb2-4b90-a505-2ef0462a9961"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Email sent to boss@company.ai with subject 'Regarding tomorrow's meeting' and content: Hi Boss,                    \n","\n","I'm writing to confirm our meeting tomorrow. I'm looking forward to it.                                            \n","\n","Best, [Your Name]                                                                                                  \n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Email sent to boss@company.ai with subject 'Regarding tomorrow's meeting' and content: Hi Boss,                    \n","\n","I'm writing to confirm our meeting tomorrow. I'm looking forward to it.                                            \n","\n","Best, [Your Name]                                                                                                  \n","</pre>\n"]},"metadata":{},"execution_count":20}],"source":["# Call the tool\n","result = write_email.invoke(args)\n","Markdown(result)"]},{"cell_type":"markdown","id":"b6f9c52a","metadata":{"id":"b6f9c52a"},"source":["![basic_prompt](img/tool_call.png)\n","\n","## Workflows\n","\n","There are many patterns for building applications with LLMs.\n","\n","[We can embed LLM calls into pre-defined workflows](https://langchain-ai.github.io/langgraph/tutorials/workflows/), giving the system more agency to make decisions.\n","\n","As an example, we could add a router step to determine whether to write an email or not.\n","\n","![workflow_example](img/workflow_example.png)\n","\n","## Agents\n","\n","We can further increase agency, allowing the LLM to dynamically direct its own tool usage.\n","\n","[Agents](https://langchain-ai.github.io/langgraph/tutorials/workflows/#agent) are typically implemented as tool calling in a loop, where the output of each tool call is used to inform the next action.\n","\n","![agent_example](img/agent_example.png)\n","\n","Agents are well suited to open-ended problems where it's difficult to predict the *exact* steps needed in advance.\n","\n","Workflows are often appropriate when the control flow can easily be defined in advance.\n","\n","![workflow_v_agent](img/workflow_v_agent.png)\n","\n","## What is LangGraph?\n","\n","[LangGraph](https://langchain-ai.github.io/langgraph/concepts/high_level/) provides low-level supporting infrastructure that sits underneath *any* workflow or agent.\n","\n","It does not abstract prompts or architecture, and provides a few benefits:\n","\n","- **Control**: Make it easy to define and / or combine agents and workflows.\n","- **Persistence**: Provide a way to persist the state of a graph, which enables both memory and human-in-the-loop.\n","- **Testing, Debugging, and Deployment**: Provide an easy onramp for testing, debugging, and deploying applications.\n","\n","### Control\n","\n","LangGraph lets you define your application as a graph with:\n","\n","1. *State*: What information do we need to track over the course of the application?\n","2. *Nodes*: How do we want to update this information over the course of the application?\n","3. *Edges*: How do we want to connect these nodes together?\n","\n","We can use the [`StateGraph` class](https://langchain-ai.github.io/langgraph/concepts/low_level/#graphs) to initialize a LangGraph graph with a [`State` object](https://langchain-ai.github.io/langgraph/concepts/low_level/#state).\n","\n","`State` defines the schema for information we want to track over the course of the application.\n","\n","This can be any object with `getattr()` in python, such as a dictionary, dataclass, or Pydantic object:\n","\n","- TypeDict is fastest but doesn’t support defaults\n","- Dataclass is basically as fast, supports dot syntax `state.foo`, and has defaults.\n","- Pydantic is slower (especially with custom validators) but gives type validation."]},{"cell_type":"code","execution_count":24,"id":"3319290a","metadata":{"id":"3319290a","executionInfo":{"status":"ok","timestamp":1755834141124,"user_tz":-480,"elapsed":81,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}}},"outputs":[],"source":["from typing import TypedDict\n","from langgraph.graph import StateGraph, START, END\n","\n","class StateSchema(TypedDict):\n","    request: str\n","    email: str\n","\n","workflow = StateGraph(StateSchema)"]},{"cell_type":"markdown","id":"b84bedb9","metadata":{"id":"b84bedb9"},"source":["Each node is simply a python function or typescript code. This gives us full control over the logic inside each node.\n","\n","They receive the current state, and return a dictionary to update the state.\n","\n","By default, [state keys are overwritten](https://langchain-ai.github.io/langgraph/how-tos/state-reducers/).\n","\n","However, you can [define custom update logic](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers).\n","\n","![nodes_edges](img/nodes_edges.png)"]},{"cell_type":"code","execution_count":25,"id":"d5e79c1f","metadata":{"id":"d5e79c1f","executionInfo":{"status":"ok","timestamp":1755834149730,"user_tz":-480,"elapsed":26,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}}},"outputs":[],"source":["def write_email_node(state: StateSchema) -> StateSchema:\n","    # Imperative code that processes the request\n","    output = model_with_tools.invoke(state[\"request\"])\n","    args = output.tool_calls[0]['args']\n","    email = write_email.invoke(args)\n","    return {\"email\": email} # update the state, it overwrites the previous value"]},{"cell_type":"markdown","id":"737c8040","metadata":{"id":"737c8040"},"source":["Edges connect nodes together.\n","\n","We specify the control flow by adding edges and nodes to our state graph."]},{"cell_type":"code","execution_count":26,"id":"554e0d8b","metadata":{"id":"554e0d8b","executionInfo":{"status":"ok","timestamp":1755834158834,"user_tz":-480,"elapsed":4,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}}},"outputs":[],"source":["workflow = StateGraph(StateSchema)\n","workflow.add_node(\"write_email_node\", write_email_node)\n","workflow.add_edge(START, \"write_email_node\")\n","workflow.add_edge(\"write_email_node\", END)\n","\n","app = workflow.compile()"]},{"cell_type":"code","execution_count":27,"id":"7cc79b40","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7cc79b40","executionInfo":{"status":"ok","timestamp":1755834162351,"user_tz":-480,"elapsed":786,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"c833d3f2-7685-4b0c-d065-79179eda5793"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'request': \"Draft a response to my boss (boss@company.ai) about tomorrow's meeting\",\n"," 'email': \"Email sent to boss@company.ai with subject 'Re: Tomorrow's Meeting' and content: Hi Boss,\\n\\nI'm looking forward to our meeting tomorrow.\\n\\nBest,\\n[Your Name]\"}"]},"metadata":{},"execution_count":27}],"source":["app.invoke({\"request\": \"Draft a response to my boss (boss@company.ai) about tomorrow's meeting\"})"]},{"cell_type":"markdown","id":"2446dea9","metadata":{"id":"2446dea9"},"source":["### Conditional Routing\n","\n","Routing between nodes can be done [conditionally](https://langchain-ai.github.io/langgraph/concepts/low_level/#conditional-edges) using a simple function.\n","\n","The return value of this function is used as the name of the node (or list of nodes) to send the state to next.\n","\n","You can optionally provide a dictionary that maps the `should_continue` output to the name of the next node."]},{"cell_type":"code","source":["!pip install html2text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hLbvIKpw5h8A","executionInfo":{"status":"ok","timestamp":1755834635431,"user_tz":-480,"elapsed":5679,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"0957a6f6-edd6-4565-e908-662bcc2651be"},"id":"hLbvIKpw5h8A","execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting html2text\n","  Downloading html2text-2025.4.15-py3-none-any.whl.metadata (4.1 kB)\n","Downloading html2text-2025.4.15-py3-none-any.whl (34 kB)\n","Installing collected packages: html2text\n","Successfully installed html2text-2025.4.15\n"]}]},{"cell_type":"code","execution_count":39,"id":"f29b05bf","metadata":{"id":"f29b05bf","executionInfo":{"status":"ok","timestamp":1755834644159,"user_tz":-480,"elapsed":50,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}}},"outputs":[],"source":["from typing import Literal\n","from langgraph.graph import MessagesState\n","from email_assistant.utils import show_graph\n","\n","def call_llm(state: MessagesState) -> MessagesState:\n","    \"\"\"Run LLM\"\"\"\n","\n","    output = model_with_tools.invoke(state[\"messages\"])\n","    return {\"messages\": [output]} # append to messages list, as suppose to overwriting previous value\n","\n","def run_tool(state: MessagesState):\n","    \"\"\"Performs the tool call\"\"\"\n","\n","    result = []\n","    for tool_call in state[\"messages\"][-1].tool_calls:\n","        observation = write_email.invoke(tool_call[\"args\"])\n","        result.append({\"role\": \"tool\", \"content\": observation, \"tool_call_id\": tool_call[\"id\"]})\n","    return {\"messages\": result}\n","\n","def should_continue(state: MessagesState) -> Literal[\"run_tool\", \"__end__\"]:\n","    \"\"\"Route to tool handler, or end if Done tool called\"\"\"\n","\n","    # Get the last message\n","    messages = state[\"messages\"]\n","    last_message = messages[-1]\n","\n","    # If the last message is a tool call, check if it's a Done tool call\n","    if last_message.tool_calls:\n","        return \"run_tool\"\n","    # Otherwise, we stop (reply to the user)\n","    return END # with conditional edges, we retrun the name of the next node you want to visit\n","    # But with nodes, we return updates to your state\n","\n","workflow = StateGraph(MessagesState)\n","workflow.add_node(\"call_llm\", call_llm)\n","workflow.add_node(\"run_tool\", run_tool)\n","workflow.add_edge(START, \"call_llm\")\n","workflow.add_conditional_edges(\"call_llm\", should_continue, {\"run_tool\": \"run_tool\", END: END})\n","workflow.add_edge(\"run_tool\", END)\n","\n","# Run the workflow\n","app = workflow.compile()"]},{"cell_type":"code","execution_count":40,"id":"fd9f07af-c633-4527-b2d9-52c6451dc9c5","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":350},"id":"fd9f07af-c633-4527-b2d9-52c6451dc9c5","executionInfo":{"status":"ok","timestamp":1755834647826,"user_tz":-480,"elapsed":191,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"8e58e787-e346-4e91-cc91-867a8ea91860"},"outputs":[{"output_type":"execute_result","data":{"image/png":"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\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{},"execution_count":40}],"source":["show_graph(app)"]},{"cell_type":"code","execution_count":41,"id":"dadbafde","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dadbafde","executionInfo":{"status":"ok","timestamp":1755834652423,"user_tz":-480,"elapsed":946,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"2b663d66-7290-4f14-b643-667fac4e80d4"},"outputs":[{"output_type":"stream","name":"stdout","text":["================================\u001b[1m Human Message \u001b[0m=================================\n","\n","Draft a response to my boss (boss@company.ai) confirming that I want to attend Interrupt!\n","==================================\u001b[1m Ai Message \u001b[0m==================================\n","Tool Calls:\n","  write_email (86664c2c-d47c-4e1d-ae98-e1dc997c92da)\n"," Call ID: 86664c2c-d47c-4e1d-ae98-e1dc997c92da\n","  Args:\n","    to: boss@company.ai\n","    content: Hi Boss,\n","\n","This email confirms that I will be attending Interrupt!.\n","\n","Thanks,\n","[Your Name]\n","    subject: Interrupt! Confirmation\n","=================================\u001b[1m Tool Message \u001b[0m=================================\n","\n","Email sent to boss@company.ai with subject 'Interrupt! Confirmation' and content: Hi Boss,\n","\n","This email confirms that I will be attending Interrupt!.\n","\n","Thanks,\n","[Your Name]\n"]}],"source":["result = app.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Draft a response to my boss (boss@company.ai) confirming that I want to attend Interrupt!\"}]})\n","for m in result[\"messages\"]:\n","    m.pretty_print()"]},{"cell_type":"markdown","id":"a78b232d","metadata":{"id":"a78b232d"},"source":["With these low level components, you can build many many different workflows and agents. See [this tutorial](https://langchain-ai.github.io/langgraph/tutorials/workflows/)!\n","\n","Because agents are such a common pattern, [LangGraph](https://langchain-ai.github.io/langgraph/tutorials/workflows/#pre-built) has [a pre-built agent](https://langchain-ai.github.io/langgraph/agents/overview/?ref=blog.langchain.dev#what-is-an-agent) abstraction.\n","\n","With LangGraph's [pre-built method](https://langchain-ai.github.io/langgraph/tutorials/workflows/#pre-built), we just pass in the LLM, tools, and prompt."]},{"cell_type":"code","execution_count":42,"id":"5a317ad8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5a317ad8","executionInfo":{"status":"ok","timestamp":1755834682460,"user_tz":-480,"elapsed":664,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"c5e95a1d-8f6c-459d-e905-2b5c96551988"},"outputs":[{"output_type":"stream","name":"stdout","text":["================================\u001b[1m Human Message \u001b[0m=================================\n","\n","Draft a response to my boss (boss@company.ai) confirming that I want to attend Interrupt!\n","==================================\u001b[1m Ai Message \u001b[0m==================================\n","\n","Okay, I can help you with that. What is the subject and content of the email you would like me to send to your boss?\n"]}],"source":["from langgraph.prebuilt import create_react_agent\n","\n","agent = create_react_agent(\n","    model=llm,\n","    tools=[write_email],\n","    prompt=\"Respond to the user's request using the tools provided.\"\n",")\n","\n","# Run the agent\n","result = agent.invoke(\n","    {\"messages\": [{\"role\": \"user\", \"content\": \"Draft a response to my boss (boss@company.ai) confirming that I want to attend Interrupt!\"}]}\n",")\n","\n","for m in result[\"messages\"]:\n","    m.pretty_print()"]},{"cell_type":"markdown","id":"3c6e506f","metadata":{"id":"3c6e506f"},"source":["### Persistence\n","\n","#### Threads\n","\n","It can be very useful to allow agents to pause during long running tasks.\n","\n","LangGraph has a built-in persistence layer, implemented through checkpointers, to enable this.\n","\n","When you compile graph with a checkpointer, the checkpointer saves a [checkpoint](https://langchain-ai.github.io/langgraph/concepts/persistence/#checkpoints) of the graph state at every step.\n","\n","Checkpoints are saved to a thread, which can be accessed after graph execution completes.\n","\n","![checkpointer](img/checkpoints.png)\n","\n","We compile the graph with a [checkpointer](https://langchain-ai.github.io/langgraph/concepts/persistence/#checkpointer-libraries).\n"]},{"cell_type":"code","execution_count":43,"id":"9a72377e","metadata":{"id":"9a72377e","executionInfo":{"status":"ok","timestamp":1755834730029,"user_tz":-480,"elapsed":816,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}}},"outputs":[],"source":["from langgraph.checkpoint.memory import InMemorySaver\n","\n","agent = create_react_agent(\n","    model=llm,\n","    tools=[write_email],\n","    prompt=\"Respond to the user's request using the tools provided.\",\n","    checkpointer=InMemorySaver()\n",")\n","\n","config = {\"configurable\": {\"thread_id\": \"1\"}}\n","result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"What are some good practices for writing emails?\"}]}, config)"]},{"cell_type":"code","execution_count":44,"id":"10984007","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"10984007","executionInfo":{"status":"ok","timestamp":1755834735485,"user_tz":-480,"elapsed":33,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"1e61ac14-2a77-45bb-c292-8186f6ea6f71"},"outputs":[{"output_type":"stream","name":"stdout","text":["================================\u001b[1m Human Message \u001b[0m=================================\n","\n","What are some good practices for writing emails?\n","==================================\u001b[1m Ai Message \u001b[0m==================================\n","\n","I can help you with that! I can write an email for you, but I don't have the capability to provide advice on good practices for writing emails.\n"]}],"source":["# Get the latest state snapshot\n","config = {\"configurable\": {\"thread_id\": \"1\"}}\n","state = agent.get_state(config)\n","for message in state.values['messages']:\n","    message.pretty_print()"]},{"cell_type":"code","execution_count":45,"id":"7f23ac58","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7f23ac58","executionInfo":{"status":"ok","timestamp":1755834746986,"user_tz":-480,"elapsed":576,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"0337803d-a4c7-4df5-94ae-e3367865af0e"},"outputs":[{"output_type":"stream","name":"stdout","text":["================================\u001b[1m Human Message \u001b[0m=================================\n","\n","What are some good practices for writing emails?\n","==================================\u001b[1m Ai Message \u001b[0m==================================\n","\n","I can help you with that! I can write an email for you, but I don't have the capability to provide advice on good practices for writing emails.\n","================================\u001b[1m Human Message \u001b[0m=================================\n","\n","Good, let's use lesson 3 to craft a response to my boss confirming that I want to attend Interrupt\n","==================================\u001b[1m Ai Message \u001b[0m==================================\n","\n","I am sorry, I do not have the ability to access lesson 3. Can you provide me with the content of the email you would like me to send to your boss?\n"]}],"source":["# Continue the conversation\n","result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Good, let's use lesson 3 to craft a response to my boss confirming that I want to attend Interrupt\"}]}, config)\n","for m in result['messages']:\n","    m.pretty_print()"]},{"cell_type":"code","execution_count":46,"id":"5f09fe50","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5f09fe50","executionInfo":{"status":"ok","timestamp":1755834755829,"user_tz":-480,"elapsed":421,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"f79ff8b4-0be6-4d6d-d8b2-5c0bf8ce72d9"},"outputs":[{"output_type":"stream","name":"stdout","text":["================================\u001b[1m Human Message \u001b[0m=================================\n","\n","What are some good practices for writing emails?\n","==================================\u001b[1m Ai Message \u001b[0m==================================\n","\n","I can help you with that! I can write an email for you, but I don't have the capability to provide advice on good practices for writing emails.\n","================================\u001b[1m Human Message \u001b[0m=================================\n","\n","Good, let's use lesson 3 to craft a response to my boss confirming that I want to attend Interrupt\n","==================================\u001b[1m Ai Message \u001b[0m==================================\n","\n","I am sorry, I do not have the ability to access lesson 3. Can you provide me with the content of the email you would like me to send to your boss?\n","================================\u001b[1m Human Message \u001b[0m=================================\n","\n","I like this, let's write the email to boss@company.ai\n","==================================\u001b[1m Ai Message \u001b[0m==================================\n","\n","Okay, I'm ready. What content and subject line would you like to use for the email to boss@company.ai?\n"]}],"source":["# Continue the conversation\n","result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"I like this, let's write the email to boss@company.ai\"}]}, config)\n","for m in result['messages']:\n","    m.pretty_print()"]},{"cell_type":"markdown","id":"4ae8a5d2-cf8a-4465-8d1b-96bb6c6276cf","metadata":{"id":"4ae8a5d2-cf8a-4465-8d1b-96bb6c6276cf"},"source":["#### Interrupts\n","\n","In LangGraph, we can also use [interrupts](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/wait-user-input/) to stop graph execution at specific points.\n","\n","Often this is used to collect input from a user and continue execution with collected input."]},{"cell_type":"code","execution_count":47,"id":"52c17b60-9474-49a5-b4a1-583b0dc8bba7","metadata":{"id":"52c17b60-9474-49a5-b4a1-583b0dc8bba7","executionInfo":{"status":"ok","timestamp":1755834778339,"user_tz":-480,"elapsed":25,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}}},"outputs":[],"source":["from typing_extensions import TypedDict\n","from langgraph.graph import StateGraph, START, END\n","\n","from langgraph.types import Command, interrupt\n","from langgraph.checkpoint.memory import InMemorySaver\n","\n","class State(TypedDict):\n","    input: str\n","    user_feedback: str\n","\n","def step_1(state):\n","    print(\"---Step 1---\")\n","    pass\n","\n","def human_feedback(state):\n","    print(\"---human_feedback---\")\n","    feedback = interrupt(\"Please provide feedback:\")\n","    return {\"user_feedback\": feedback}\n","\n","def step_3(state):\n","    print(\"---Step 3---\")\n","    pass\n","\n","builder = StateGraph(State)\n","builder.add_node(\"step_1\", step_1)\n","builder.add_node(\"human_feedback\", human_feedback)\n","builder.add_node(\"step_3\", step_3)\n","builder.add_edge(START, \"step_1\")\n","builder.add_edge(\"step_1\", \"human_feedback\")\n","builder.add_edge(\"human_feedback\", \"step_3\")\n","builder.add_edge(\"step_3\", END)\n","\n","# Set up memory\n","memory = InMemorySaver()\n","\n","# Add\n","graph = builder.compile(checkpointer=memory)"]},{"cell_type":"code","execution_count":48,"id":"57c94cb7-067c-4bc5-be33-b615d8e5775e","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":449},"id":"57c94cb7-067c-4bc5-be33-b615d8e5775e","executionInfo":{"status":"ok","timestamp":1755834781805,"user_tz":-480,"elapsed":193,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"f699383b-25ca-41f1-b954-1417d813b815"},"outputs":[{"output_type":"execute_result","data":{"image/png":"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\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{},"execution_count":48}],"source":["show_graph(graph)"]},{"cell_type":"code","execution_count":49,"id":"028372b5-88ae-4f13-813d-22430a697f07","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"028372b5-88ae-4f13-813d-22430a697f07","executionInfo":{"status":"ok","timestamp":1755834831714,"user_tz":-480,"elapsed":44,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"134da3ea-9292-4999-c352-19784972485a"},"outputs":[{"output_type":"stream","name":"stdout","text":["---Step 1---\n","{'step_1': None}\n","\n","\n","---human_feedback---\n","{'__interrupt__': (Interrupt(value='Please provide feedback:', id='b98c366d43ae884467a01863ed16dc00'),)}\n","\n","\n"]}],"source":["# Input\n","initial_input = {\"input\": \"hello world\"}\n","\n","# Thread\n","thread = {\"configurable\": {\"thread_id\": \"1\"}}\n","\n","# Run the graph until the first interruption\n","for event in graph.stream(initial_input, thread, stream_mode=\"updates\"):\n","    print(event)\n","    print(\"\\n\")"]},{"cell_type":"markdown","id":"f142d467-7b4c-4a04-bad5-bf3fbe953b84","metadata":{"id":"f142d467-7b4c-4a04-bad5-bf3fbe953b84"},"source":["To resume from an interrupt, we can use [the `Command` object](https://langchain-ai.github.io/langgraph/how-tos/command/).\n","\n","We'll use it to resume the graph from the interrupted state, passing the value to return from the interrupt call to `resume`."]},{"cell_type":"code","execution_count":50,"id":"d90374d3-65a1-4658-82ee-a16cc2835cf4","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d90374d3-65a1-4658-82ee-a16cc2835cf4","executionInfo":{"status":"ok","timestamp":1755834838667,"user_tz":-480,"elapsed":31,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"e21b8ce0-6632-4c16-e39b-d437056801e7"},"outputs":[{"output_type":"stream","name":"stdout","text":["---human_feedback---\n","{'human_feedback': {'user_feedback': 'go to step 3!'}}\n","\n","\n","---Step 3---\n","{'step_3': None}\n","\n","\n"]}],"source":["# Continue the graph execution\n","for event in graph.stream(\n","    Command(resume=\"go to step 3!\"),\n","    thread,\n","    stream_mode=\"updates\",\n","):\n","    print(event)\n","    print(\"\\n\")"]},{"cell_type":"markdown","id":"8639a518","metadata":{"id":"8639a518"},"source":["### Tracing\n","\n","When we are using LangChain or LangGraph, LangSmith logging [will work out of the box](https://docs.smith.langchain.com/observability/how_to_guides/trace_with_langgraph) with the following environment variables set:\n","\n","```\n","export LANGSMITH_TRACING=true\n","export LANGSMITH_API_KEY=\"<your-langsmith-api-key>\"\n","```"]},{"cell_type":"markdown","id":"9cb2a3e5","metadata":{"id":"9cb2a3e5"},"source":["Here is the LangSmith trace from above agent execution:\n","\n","https://smith.langchain.com/public/6f77014f-d054-44ed-aa2c-8b06ceab689f/r\n","\n","We can see that the agent is able to continue the conversation from the previous state because we used a checkpointer."]},{"cell_type":"markdown","id":"f0269214","metadata":{"id":"f0269214"},"source":["### Deployment\n","\n","We can also deploy our graph using [LangGraph Platform](https://langchain-ai.github.io/langgraph/concepts/langgraph_platform/).\n","\n","This creates a server [with an API](https://langchain-ai.github.io/langgraph/cloud/reference/api/api_ref.html) that we can use to interact with our graph and an interactive IDE, LangGraph [Studio](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/).\n","\n","We simply need to ensure our project has [a structure](https://langchain-ai.github.io/langgraph/concepts/application_structure/) like this:\n","\n","```\n","my-app/\n","├── src/email_assistant # all project code lies within here\n","│   └── langgraph101.py # code for constructing your graph\n","├── .env # environment variables\n","├── langgraph.json  # configuration file for LangGraph\n","└── pyproject.toml # dependencies for your project\n","```\n","\n","The `langgraph.json` file specifies the dependencies, graphs, environment variables, and other settings required to start a LangGraph server.\n","\n","To test this, let's deploy `langgraph_101.py`. We have it in our `langgraph.json` file in this repo:\n","\n","```\n"," \"langgraph101\": \"./src/email_assistant/langgraph_101.py:app\",\n","```\n","\n","For LangGraph Platform, there are a range of [deployment options](https://langchain-ai.github.io/langgraph/tutorials/deployment/):\n","\n","* Local deployments can be started with `langgraph dev` from the root directory of the repo. Checkpoints are saved to the local filesystem.\n","* There are also various [self-hosted options](https://langchain-ai.github.io/langgraph/tutorials/deployment/#other-deployment-options).\n","* For hosted deployments, checkpoints are saved to Postgres using a postgres [checkpointer](https://langchain-ai.github.io/langgraph/concepts/persistence/#checkpointer-libraries).\n","\n","Test:\n","```\n","Draft a response to my boss (boss@company.ai) confirming that I want to attent Interrupt!\n","```"]},{"cell_type":"code","source":["# Python >= 3.11 is required.\n","\n","!pip install --upgrade \"langgraph-cli[inmem]\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LT71zJYLBAKW","executionInfo":{"status":"ok","timestamp":1755836599665,"user_tz":-480,"elapsed":10074,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"faf4c6b0-1f34-4996-d7a6-f943b8b53e0a"},"id":"LT71zJYLBAKW","execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langgraph-cli[inmem]\n","  Downloading langgraph_cli-0.3.8-py3-none-any.whl.metadata (3.8 kB)\n","Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.12/dist-packages (from langgraph-cli[inmem]) (8.2.1)\n","Requirement already satisfied: langgraph-sdk>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-cli[inmem]) (0.2.3)\n","Collecting langgraph-api<0.4.0,>=0.2.120 (from langgraph-cli[inmem])\n","  Downloading langgraph_api-0.3.1-py3-none-any.whl.metadata (3.9 kB)\n","Collecting langgraph-runtime-inmem>=0.6.8 (from langgraph-cli[inmem])\n","  Downloading langgraph_runtime_inmem-0.8.1-py3-none-any.whl.metadata (565 bytes)\n","Requirement already satisfied: python-dotenv>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-cli[inmem]) (1.1.1)\n","Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem]) (3.1.1)\n","Requirement already satisfied: cryptography<45.0,>=42.0.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem]) (43.0.3)\n","Requirement already satisfied: httpx>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem]) (0.28.1)\n","Collecting jsonschema-rs<0.30,>=0.20.0 (from langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem])\n","  Downloading jsonschema_rs-0.29.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n","Requirement already satisfied: langchain-core>=0.3.64 in /usr/local/lib/python3.12/dist-packages (from langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem]) (0.3.74)\n","Requirement already satisfied: langgraph-checkpoint>=2.0.23 in /usr/local/lib/python3.12/dist-packages (from langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem]) (2.1.1)\n","Requirement already satisfied: langgraph>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem]) (0.6.6)\n","Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem]) (0.4.14)\n","Requirement already satisfied: orjson>=3.9.7 in /usr/local/lib/python3.12/dist-packages (from langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem]) (3.11.2)\n","Requirement already satisfied: pyjwt>=2.9.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem]) (2.10.1)\n","Collecting sse-starlette<2.2.0,>=2.1.0 (from langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem])\n","  Downloading sse_starlette-2.1.3-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: starlette>=0.38.6 in /usr/local/lib/python3.12/dist-packages (from langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem]) (0.47.2)\n","Collecting structlog<26,>=24.1.0 (from langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem])\n","  Downloading structlog-25.4.0-py3-none-any.whl.metadata (7.6 kB)\n","Requirement already satisfied: tenacity>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem]) (8.5.0)\n","Collecting truststore>=0.1 (from langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem])\n","  Downloading truststore-0.10.4-py3-none-any.whl.metadata (4.4 kB)\n","Requirement already satisfied: uvicorn>=0.26.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem]) (0.35.0)\n","Collecting watchfiles>=0.13 (from langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem])\n","  Downloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Collecting blockbuster<2.0.0,>=1.5.24 (from langgraph-runtime-inmem>=0.6.8->langgraph-cli[inmem])\n","  Downloading blockbuster-1.5.25-py3-none-any.whl.metadata (10 kB)\n","Collecting forbiddenfruit>=0.1.4 (from blockbuster<2.0.0,>=1.5.24->langgraph-runtime-inmem>=0.6.8->langgraph-cli[inmem])\n","  Downloading forbiddenfruit-0.1.4.tar.gz (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography<45.0,>=42.0.0->langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem]) (1.17.1)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.0->langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem]) (4.10.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.0->langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem]) (2025.8.3)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.0->langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem]) (1.0.9)\n","Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.0->langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem]) (3.10)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.0->langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem]) (0.16.0)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.64->langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem]) (1.33)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.64->langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem]) (6.0.2)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.64->langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem]) (4.14.1)\n","Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.64->langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem]) (25.0)\n","Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.64->langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem]) (2.11.7)\n","Requirement already satisfied: langgraph-prebuilt<0.7.0,>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from langgraph>=0.4.0->langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem]) (0.6.4)\n","Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph>=0.4.0->langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem]) (3.5.0)\n","Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint>=2.0.23->langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem]) (1.10.0)\n","Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem]) (1.0.0)\n","Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem]) (2.32.4)\n","Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem]) (0.24.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.0->langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem]) (1.3.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography<45.0,>=42.0.0->langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem]) (2.22)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.3.64->langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem]) (3.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core>=0.3.64->langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem]) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core>=0.3.64->langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem]) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core>=0.3.64->langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem]) (0.4.1)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem]) (3.4.3)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langgraph-api<0.4.0,>=0.2.120->langgraph-cli[inmem]) (2.5.0)\n","Downloading langgraph_api-0.3.1-py3-none-any.whl (206 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.0/206.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langgraph_runtime_inmem-0.8.1-py3-none-any.whl (31 kB)\n","Downloading langgraph_cli-0.3.8-py3-none-any.whl (37 kB)\n","Downloading blockbuster-1.5.25-py3-none-any.whl (13 kB)\n","Downloading jsonschema_rs-0.29.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sse_starlette-2.1.3-py3-none-any.whl (9.4 kB)\n","Downloading structlog-25.4.0-py3-none-any.whl (68 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.7/68.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading truststore-0.10.4-py3-none-any.whl (18 kB)\n","Downloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.2/452.2 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: forbiddenfruit\n","  Building wheel for forbiddenfruit (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for forbiddenfruit: filename=forbiddenfruit-0.1.4-py3-none-any.whl size=21789 sha256=ea106eac203653edbd05b80091bd03b5a66adad995eac3f8db40370f78b577bb\n","  Stored in directory: /root/.cache/pip/wheels/eb/1b/4e/1720775f695118457d0692cea72b8be2b8af2a7bae46611e93\n","Successfully built forbiddenfruit\n","Installing collected packages: forbiddenfruit, truststore, structlog, jsonschema-rs, blockbuster, watchfiles, sse-starlette, langgraph-cli, langgraph-runtime-inmem, langgraph-api\n","  Attempting uninstall: sse-starlette\n","    Found existing installation: sse-starlette 3.0.2\n","    Uninstalling sse-starlette-3.0.2:\n","      Successfully uninstalled sse-starlette-3.0.2\n","Successfully installed blockbuster-1.5.25 forbiddenfruit-0.1.4 jsonschema-rs-0.29.1 langgraph-api-0.3.1 langgraph-cli-0.3.8 langgraph-runtime-inmem-0.8.1 sse-starlette-2.1.3 structlog-25.4.0 truststore-0.10.4 watchfiles-1.1.0\n"]}]},{"cell_type":"code","source":["!"],"metadata":{"id":"eEblBiOiBENN"},"id":"eEblBiOiBENN","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"f3644093","metadata":{"id":"f3644093"},"source":["Here we can see a visualization of the graph as well as the graph state in Studio.\n","\n","![langgraph_studio](img/langgraph_studio.png)\n","\n","Also, you can see API docs for the local deployment here:\n","\n","http://127.0.0.1:2024/docs"]}],"metadata":{"jupytext":{"cell_metadata_filter":"-all","main_language":"python","notebook_metadata_filter":"-all"},"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}