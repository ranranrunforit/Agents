{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aw73Xhwc9di7"
   },
   "source": [
    "# Dataset Upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9R_Dakoy9di8"
   },
   "source": [
    "In addition to creating and editing Datasets in the LangSmith UI, you can also create and edit datasets with the LangSmith SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thBXf2Ib9di-"
   },
   "source": [
    "Let's go ahead an upload a list of examples that we have from our RAG application to LangSmith as a new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34171,
     "status": "ok",
     "timestamp": 1756703322518,
     "user": {
      "displayName": "Chaoran Zhou",
      "userId": "09162553986537566448"
     },
     "user_tz": -480
    },
    "id": "pOIAnY-oGxnX",
    "outputId": "802c109b-a1bd-47ed-bf7c-42293ad5c464"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m378.5/378.5 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.0/444.0 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.6/151.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
      "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install --quiet -U langchain-google-genai langgraph langgraph-sdk langgraph-checkpoint-sqlite langsmith langchain-community langchain-core\n",
    "!pip install --quiet notebook python-dotenv lxml scikit-learn pandas pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 7797,
     "status": "ok",
     "timestamp": 1756703342418,
     "user": {
      "displayName": "Chaoran Zhou",
      "userId": "09162553986537566448"
     },
     "user_tz": -480
    },
    "id": "n9k9ZKUaHA5l"
   },
   "outputs": [],
   "source": [
    "!pip install --quiet python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 522,
     "status": "ok",
     "timestamp": 1756703342943,
     "user": {
      "displayName": "Chaoran Zhou",
      "userId": "09162553986537566448"
     },
     "user_tz": -480
    },
    "id": "nB4-CZXlHAbB",
    "outputId": "8d4af1da-b1e9-4434-e85d-bb1f35d7e9a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tUQhLCW79di_"
   },
   "outputs": [],
   "source": [
    "# You can set them inline\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"langsmith-academy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LrKRQvXT9djA"
   },
   "outputs": [],
   "source": [
    "# Or you can use a .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"../../.env\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1756703626325,
     "user": {
      "displayName": "Chaoran Zhou",
      "userId": "09162553986537566448"
     },
     "user_tz": -480
    },
    "id": "YExX0Anp9djC",
    "outputId": "7c304caa-1637-42d0-dd7e-7ab635d476b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'example_ids': ['7c858c38-14b0-4503-a836-b44efe38513c',\n",
       "  'b2822d2a-ae86-4f28-9d98-5777f097697d',\n",
       "  '17faded4-3541-4b1c-8743-d6bcca435958',\n",
       "  '1259cfcc-05ca-43f2-a82c-813e4064881d',\n",
       "  '6b3a736a-7a0e-48d7-a5ad-e752cc334d3f',\n",
       "  '0152c119-1cf5-4150-ac52-4fee77387f9a',\n",
       "  '1462cb35-590d-4e93-9258-a68b6c1fbbe0',\n",
       "  '2b5dc92e-e546-4970-9c43-725d0c4078d9',\n",
       "  'b892ff56-efa7-4773-8b6d-68d83685036a',\n",
       "  'cd044d22-876e-4265-a254-303fc394550e'],\n",
       " 'count': 10}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "example_inputs = [\n",
    "(\"How do I set up tracing to LangSmith if I'm using LangChain?\", \"To set up tracing to LangSmith while using LangChain, you need to set the environment variable `LANGSMITH_TRACING` to 'true'. Additionally, you must set the `LANGSMITH_API_KEY` environment variable to your API key. By default, traces will be logged to a project named \\\"default.\\\"\"),\n",
    "(\"How can I trace with the @traceable decorator?\", \"To trace with the @traceable decorator in Python, simply decorate any function you want to log traces for by adding `@traceable` above the function definition. Ensure that the LANGSMITH_TRACING environment variable is set to 'true' to enable tracing, and also set the LANGSMITH_API_KEY environment variable with your API key. By default, traces will be logged to a project named \\\"default,\\\" but you can configure it to log to a different project if needed.\"),\n",
    "(\"How do I pass metadata in with @traceable?\", \"You can pass metadata with the @traceable decorator by specifying arbitrary key-value pairs as arguments. This allows you to associate additional information, such as the execution environment or user details, with your traces. For more detailed instructions, refer to the LangSmith documentation on adding metadata and tags.\"),\n",
    "(\"What is LangSmith used for in three sentences?\", \"LangSmith is a platform designed for the development, monitoring, and testing of LLM applications. It enables users to collect and analyze unstructured data, debug issues, and create datasets for testing and evaluation. The tool supports various workflows throughout the application development lifecycle, enhancing the overall performance and reliability of LLM applications.\"),\n",
    "(\"What testing capabilities does LangSmith have?\", \"LangSmith offers capabilities for creating datasets of inputs and reference outputs to run tests on LLM applications, supporting a test-driven approach. It allows for bulk uploads of test cases, on-the-fly creation, and exporting from application traces. Additionally, LangSmith facilitates custom evaluations to score test results, enhancing the testing process.\"),\n",
    "(\"Does LangSmith support online evaluation?\", \"Yes, LangSmith supports online evaluation as a feature. It allows you to configure a sample of runs from production to be evaluated, providing feedback on those runs. You can use either custom code or an LLM as a judge for the evaluations.\"),\n",
    "(\"Does LangSmith support offline evaluation?\", \"Yes, LangSmith supports offline evaluation through its evaluation how-to guides and features for managing datasets. Users can manage datasets for offline evaluations and run various types of evaluations, including unit testing and auto-evaluation. This allows for comprehensive testing and improvement of LLM applications.\"),\n",
    "(\"Can LangSmith be used for finetuning and model training?\", \"Yes, LangSmith can be used for fine-tuning and model training. It allows you to capture run traces from your deployment, query and filter this data, and convert it into a format suitable for fine-tuning models. Additionally, you can create training datasets to keep track of the data used for model training.\"),\n",
    "(\"Can LangSmith be used to evaluate agents?\", \"Yes, LangSmith can be used to evaluate agents. It provides various evaluation strategies, including assessing the agent's final response, evaluating individual steps, and analyzing the trajectory of tool calls. These methods help ensure the effectiveness of LLM applications.\"),\n",
    "(\"How do I create user feedback with the LangSmith sdk?\", \"To create user feedback with the LangSmith SDK, you first need to run your application and obtain the `run_id`. Then, you can use the `create_feedback` method, providing the `run_id`, a feedback key, a score, and an optional comment. For example, in Python, it would look like this: `client.create_feedback(run_id, key=\\\"feedback-key\\\", score=1.0, comment=\\\"comment\\\")`.\"),\n",
    "]\n",
    "\n",
    "client = Client()\n",
    "# TODO: Fill in dataset id\n",
    "dataset_id = \"79400911-becd-44c0-87c1-3e13372ccf15\"\n",
    "\n",
    "# Prepare inputs and outputs for bulk creation\n",
    "inputs = [{\"question\": input_prompt} for input_prompt, _ in example_inputs]\n",
    "outputs = [{\"output\": output_answer} for _, output_answer in example_inputs]\n",
    "\n",
    "client.create_examples(\n",
    "  inputs=inputs,\n",
    "  outputs=outputs,\n",
    "  dataset_id=dataset_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7B6T6LN9djD"
   },
   "source": [
    "## Submitting another Trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2NmkmSHU9djE"
   },
   "source": [
    "I've moved our RAG application definition to `app.py` so we can quickly import it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615,
     "referenced_widgets": [
      "5eb271a49c184decb0039a39dff4114f",
      "0b597f36c3404a149775beccdc03c764",
      "efacf9b2012948b082e526dd584b8a48",
      "34658935bf53423b95a6f7f37eb7ae83",
      "775098e2884a4c8cbadd12e7d8528f58",
      "59238a55787340069dc814f4be3f1daa",
      "bbca82d434734030b7475741b8e02ea3",
      "f02d1270ec894d289b03432e0ef158d3",
      "c3c51a141ad445b8b9653c87745fc6c5",
      "87074ad0a2b44abf8643dd03d34c38a4",
      "d55b8438262041199dcfc91f23dd9e22",
      "6cf7e0e5b1c846b2a1f1baaa232a48d3",
      "1caa27f5b75d447687433fdc8d3b5a4a",
      "b7873f371d654f5cbaf3e71caa95b139",
      "ef534a96d320499e9ab9546a6e10ee9e",
      "7d852f7c688f49958c104dc5d4bfb568",
      "60fe514f59bb44a487230ae8deb77a5b",
      "59275499c027406997664c6901d84887",
      "544da2f4357e44369d5299425973cee1",
      "f22d0307e4f844ba8ad3e998c4375797",
      "d7099a8fe2694ee280655bae63fc9318",
      "44c96a65f4b74868b428eb721f5c00f7",
      "2c1f517510b04420960d64150c234abb",
      "f1054438807b4a0a8aa5ecea6ecd2764",
      "0115fb2580c94ee28b73dfee6f90d6b6",
      "522cb2f9e9474440922e617ebfe3bf6e",
      "f35b14e5d2dc4fe5975efab126635c6a",
      "0adfa92863624ae7b1737470fe3ba047",
      "a4d2fd0c73da41969fad439d9669384c",
      "a6bcfdcbc18c41e09207186fcda2f302",
      "b400d4f1f0aa4bc89495940552c838ef",
      "f8d0e78b517f4d3a962d5ee40954fc53",
      "41d5afbb602e4ae1b73dab7b732df99e",
      "8801440a29de42b983f06bfe75ebb9b8",
      "5cac7c8059d247458b34fc73864dc969",
      "3a187e8c63d44137a40d0a4c9a584ec5",
      "020378809a304ea2a09561d505afd11b",
      "dd148bd886f74c8aa8115f473cfb3fe2",
      "ef13f17e1ac84b12ba71e7acc6792c58",
      "e2451bc156a34a06a5bf2bb899c4d78c",
      "54857d11117f4d99af03fbd9538a11c6",
      "595f50eda305410db959c3b66fe9964f",
      "819d1c6a01494381b19d084b3673e507",
      "ea86d2377c714a7f8fe1203d6a961ca4",
      "af158d802280491791159c024ca333ac",
      "77b42bd5453d48389aab6326ca9dbf94",
      "8b2286fa4c894b5e86ab8f63fab8f464",
      "81805e26089f4fbf8615b1a0f2b3344e",
      "28d63634d5d94c2183222e3e01943ac3",
      "435527b19dd741e397af7636a627cf4b",
      "7310416e17a94be7aa86d120130a2be0",
      "d31d8479956f452eb1996ab6483f8369",
      "bb173826766244899049c2efaa097cd8",
      "ffc9d1a5ae87490b88cba9a37c370a30",
      "dfbb078c37664eed8928907d9c8b66ce",
      "a7b13e9a796d4deab41ac3d8268c7098",
      "2bbd7c6933d14af58da87258b361e27b",
      "251c6ba0b722481c9e5649e37d0150d7",
      "d135e7a0d420429c8343d5e186328bcb",
      "f978a8851b744009b6d89d9976ddddc2",
      "c9a3774026294b9ea56f43aa02a4320e",
      "bcf320d3771a4c78b850bc76c0a6d99e",
      "667178df93544903a5109e0c3568f391",
      "6d783dc47b594e75ade777e46329e294",
      "ce0ac1251bb44803b267450adf498d7a",
      "853e95771e164d79b5173603aa3966d7",
      "da2f529980844caaac8d9a6ebfc47b0f",
      "8bc5b4998359481cbd72314a2dbc9ef7",
      "02fbbcc3017541c0af04e8cfa50c966d",
      "646eb925cf7f435b883b6669a1cee757",
      "081d96702243492293f144e65405fadb",
      "59e3644168624b909d725eee19f60014",
      "024081fd846a4d9892f813ca9f12f180",
      "8d231894fca24c9d974db5227acf1137",
      "38c2fa7f34d547f4b883d171e1ae05b5",
      "de93f2d6044e4c1e9452fca5ecab0948",
      "832b2f4a321c4d5fbb67c90390e989c6",
      "7f4efe26976347ae809b05630b6ed9ce",
      "62ee4173ff2345f8b62ab4cfcb3c62dc",
      "efaf8958b9cc4a58939e97f7053e82a7",
      "8a2048915dd94c97921cee1cdea95030",
      "3cc759ea9efc42059b55979ff38c8597",
      "1ad649368062469a9c9d2dbcb72993ef",
      "ae71d7673e8848f6939a4f2798d49e77",
      "e36b073b01a6447a98c15e6730f1bd44",
      "96a6f8239c9a41b4bab8b81a35ec0671",
      "64d6e20eba444397bbb70a4c5fce9202",
      "cd24c3cc89dc4260a385d5b7d91b4357",
      "d37b4c79763943219146c55645f3d532",
      "56fa0c4002b84607aaaa15a8d7925ffb",
      "d80a3238ce2e41769400cbf29ac4d2af",
      "ab9ed646705548a2b30611cde83fe052",
      "db83c0a02e6f4a199abc0445e88dfe7c",
      "bb6b1110acd84148908e697d4e22386d",
      "7e594c124f144737925146b4b6dff6ed",
      "4dae77df2897489f940cf15a3245add9",
      "9d3f1fab6dfc46c3837d17c6480c865c",
      "e725f7f0c23f4c5e82330d64656835b8",
      "9e6488f3ff094f7fb5377909e437822d",
      "e1f6d153df3e4e08be011d3364b31ffd",
      "2017fbc4aad44c7ca5df4c14642441b1",
      "4407d824fd75460ba55f0dedb1bce1ce",
      "cf930ebc4c3b4da99ced4cbbf1a88a38",
      "672ce7ee374641a1b94886811b0ae166",
      "dbf306b6740c48aa93928f7b5f720f1d",
      "b1bdd3515737476e864ee659b85258fc",
      "8ac6733f716045cb8db8f0d447d73f46",
      "571590a65ec04bc8b412e3755b0c5410",
      "d90262aa508b4ebb97c590fc5452993b",
      "a69daad974a3492c8ad2ccb3cbf543ba",
      "9c54d8a1880846048398646e0251d801",
      "f25c26c386ab4590bb9a8415de3ed9e9",
      "7323a465992647648ad8b31a42af9bc1",
      "72b8ee1bada44656b49f6d47cb014fc9",
      "5e9e5e80c7fa43f39c961c1d2c49b778",
      "4a1e6ceca3034d469cf9f0b02db0814b",
      "a3e01c54891c442ca2065dfe1fbb480f",
      "c19f34a747864921a0fa3ff5ca21a0dd",
      "86dab9a518214406b70d8c1c691c8c23",
      "73e305d5118041c5825cb10f0b5eea22",
      "08732db332034e059a8f7f4f662fa82b"
     ]
    },
    "executionInfo": {
     "elapsed": 215135,
     "status": "ok",
     "timestamp": 1756704107183,
     "user": {
      "displayName": "Chaoran Zhou",
      "userId": "09162553986537566448"
     },
     "user_tz": -480
    },
    "id": "-u1VKaKN9djF",
    "outputId": "3fbab675-e16f-4a35-be01-55220abdec78"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "/content/drive/MyDrive/Colab Notebooks/intro-to-langsmith-main/notebooks/module_2/app.py:46: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embd = HuggingFaceEmbeddings(\n",
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb271a49c184decb0039a39dff4114f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cf7e0e5b1c846b2a1f1baaa232a48d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c1f517510b04420960d64150c234abb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8801440a29de42b983f06bfe75ebb9b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af158d802280491791159c024ca333ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b13e9a796d4deab41ac3d8268c7098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da2f529980844caaac8d9a6ebfc47b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f4efe26976347ae809b05630b6ed9ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37b4c79763943219146c55645f3d532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1f6d153df3e4e08be011d3364b31ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c54d8a1880846048398646e0251d801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing vector store found. Indexing documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching pages: 100%|##########| 197/197 [00:24<00:00,  7.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 1174 document splits. Creating vector store...\n",
      "Persisting vector store to: /tmp/union_local.parquet\n"
     ]
    }
   ],
   "source": [
    "from app import langsmith_rag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DiYhT_V_9djG"
   },
   "source": [
    "Let's ask another question to create a new trace!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "executionInfo": {
     "elapsed": 4251,
     "status": "ok",
     "timestamp": 1756704135395,
     "user": {
      "displayName": "Chaoran Zhou",
      "userId": "09162553986537566448"
     },
     "user_tz": -480
    },
    "id": "oeIKdDl-9djG",
    "outputId": "e8d48a8e-28b8-4554-c090-40aebd6c0039"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"To set up tracing for a LangChain application to LangSmith, first install `langsmith[otel]` and `langchain`. Then, enable the OpenTelemetry integration by setting the environment variables `LANGSMITH_OTEL_ENABLED=true`, `LANGSMITH_TRACING=true`, `LANGSMITH_ENDPOINT`, and `LANGSMITH_API_KEY`. Once these are configured, your LangChain application's traces will be logged to your LangSmith dashboard automatically when it runs.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"How do I set up tracing to LangSmith if I'm using LangChain?\"\n",
    "langsmith_rag(question)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ls-academy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
