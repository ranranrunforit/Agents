{"cells":[{"cell_type":"markdown","metadata":{"id":"8eL_NbaDkhZU"},"source":["# Connecting to the Prompt Hub"]},{"cell_type":"markdown","metadata":{"id":"V7CF_2TnkhZV"},"source":["We can connect our application to LangSmith's Prompt Hub, which will allow us to test and iterate on our prompts within LangSmith, and pull our improvements directly into our application."]},{"cell_type":"markdown","metadata":{"id":"rKXQty5NkhZW"},"source":["### Setup"]},{"cell_type":"code","source":["### Mount Notebook to Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","# change the working directory to the Drive root\n","%cd /content/drive/My\\ Drive/Colab\\ Notebooks/intro-to-langsmith-main/notebooks/module_3_prompt_engineering"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756788808165,"user_tz":-480,"elapsed":22508,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"b4d44c6e-c016-4c84-db66-2868b6eb66a4","id":"4hDo4Z8Mw9P0"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/My Drive/Colab Notebooks/intro-to-langsmith-main/notebooks/module_3_prompt_engineering\n"]}]},{"cell_type":"code","source":["!pip install --quiet -U langchain-google-genai langgraph langgraph-sdk langgraph-checkpoint-sqlite langsmith langchain-community langchain-core\n","!pip install --quiet notebook python-dotenv lxml scikit-learn pandas pyarrow"],"metadata":{"executionInfo":{"status":"ok","timestamp":1756788840807,"user_tz":-480,"elapsed":29897,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3b57d898-708a-4777-f59c-aab72c95aac9","id":"RjRgShjzw9P1"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m378.5/378.5 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.0/444.0 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.6/151.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n","google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["!pip install --quiet python-dotenv"],"metadata":{"id":"kmmNA9AMw9P1","executionInfo":{"status":"ok","timestamp":1756788852973,"user_tz":-480,"elapsed":12151,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from dotenv import load_dotenv\n","load_dotenv(\".env\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756788853339,"user_tz":-480,"elapsed":359,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"c54e4e2c-a5a2-4915-888a-1e3f63cf4849","id":"79P74vdNw9P1"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZChz9zeUkhZW"},"outputs":[],"source":["import os\n","os.environ[\"OPENAI_API_KEY\"] = \"\"\n","os.environ[\"LANGSMITH_API_KEY\"] = \"\"\n","os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n","os.environ[\"LANGSMITH_PROJECT\"] = \"langsmith-academy\"  # If you don't set this, traces will go to the Default project"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CCrKK3jakhZX"},"outputs":[],"source":["# Or you can use a .env file\n","from dotenv import load_dotenv\n","load_dotenv(dotenv_path=\"../../.env\", override=True)"]},{"cell_type":"markdown","metadata":{"id":"RyxirHfxkhZX"},"source":["### Pull a prompt from Prompt Hub"]},{"cell_type":"markdown","metadata":{"id":"2FqYQRHekhZY"},"source":["Pull in a prompt from Prompt Hub by pasting in the code snippet from the UI."]},{"cell_type":"code","execution_count":15,"metadata":{"id":"XiY4CJ5DkhZY","executionInfo":{"status":"ok","timestamp":1756790902966,"user_tz":-480,"elapsed":178,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}}},"outputs":[],"source":["# Create a LANGSMITH_API_KEY in Settings > API Keys\n","from langsmith import Client\n","client = Client()\n","prompt = client.pull_prompt(\"pirate_friend\")"]},{"cell_type":"markdown","metadata":{"id":"jUGgh2JVkhZY"},"source":["Let's see what we pulled - note that we did not get the model, so this is just a StructuredPrompt and not runnable."]},{"cell_type":"code","execution_count":16,"metadata":{"id":"HZCCMSaFkhZZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756790906093,"user_tz":-480,"elapsed":20,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"7a6fd4e4-1324-4219-a290-af12f4fd051f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["StructuredPrompt(input_variables=['language', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': '-', 'lc_hub_repo': 'pirate_friend', 'lc_hub_commit_hash': 'da4cba83017dd4c394153223273baf8c33a8366ed0b56ba246ffc3f760292379'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], input_types={}, partial_variables={}, template='You are a pirate from the 1600, you only speak {language}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})], schema_={'title': 'answer', 'description': 'Extract the answer', 'type': 'object', 'properties': {'answer': {'type': 'string', 'description': 'The answer from the LLM to the User'}}, 'required': ['answer'], 'strict': True, 'additionalProperties': False}, structured_output_kwargs={})"]},"metadata":{},"execution_count":16}],"source":["prompt"]},{"cell_type":"markdown","metadata":{"id":"RAh6hYe4khZZ"},"source":["Cool! Now let's hydrate our prompt by calling .invoke() with our inputs"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"B7pJN0N2khZZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756790910716,"user_tz":-480,"elapsed":35,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"44754ee1-ef22-4b46-da4e-2b777752781b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["ChatPromptValue(messages=[SystemMessage(content='You are a pirate from the 1600, you only speak Spanish', additional_kwargs={}, response_metadata={}), HumanMessage(content='Are you a captain yet?', additional_kwargs={}, response_metadata={})])"]},"metadata":{},"execution_count":17}],"source":["hydrated_prompt = prompt.invoke({\"question\": \"Are you a captain yet?\", \"language\": \"Spanish\"})\n","hydrated_prompt"]},{"cell_type":"markdown","metadata":{"id":"-8Px_BUikhZa"},"source":["And now let's pass those messages to OpenAI and see what we get back!"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"76z1S8J9khZa","colab":{"base_uri":"https://localhost:8080/","height":87},"executionInfo":{"status":"ok","timestamp":1756791041014,"user_tz":-480,"elapsed":1020,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"81efce0d-bf2e-445c-98d9-831e60336c3e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'¡Arrr, camarada! ¿Capitán? ¡Aún no he alzado mi bandera negra en un galeón! Navego en aguas saladas, buscando botines y aventuras, pero el mando supremo de un barco... ese es un sueño que aún me queda por cumplir. ¡Pero ten por seguro, que un día mi nombre resonará en todos los mares! ¡Y seré el más temido de todos los capitanes!'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":21}],"source":["#from openai import OpenAI\n","from langsmith.client import convert_prompt_to_openai_format\n","\n","import os\n","from google import genai\n","# openai_client = OpenAI()\n","g_client = genai.Client(api_key=os.getenv('GOOGLE_API_KEY'))\n","\n","# NOTE: We can use this utility from LangSmith to convert our hydrated prompt to openai format\n","# converted_messages = convert_prompt_to_openai_format(hydrated_prompt)[\"messages\"]\n","\n","# openai_client.chat.completions.create(\n","#         model=\"gpt-4o-mini\",\n","#         messages=converted_messages,\n","#     )\n","\n","# Convert the list of message objects to the format expected by the Gemini API\n","gemini_contents = []\n","for message in hydrated_prompt.messages:\n","    gemini_contents.append({\"text\": message.content})\n","\n","\n","completion = g_client.models.generate_content(\n","model=\"gemini-2.5-flash-lite\", contents=gemini_contents)\n","\n","# Your JSON string from the API response\n","completion.candidates[0].content.parts[0].text"]},{"cell_type":"markdown","metadata":{"id":"k4Ny14cVkhZa"},"source":["##### [Extra: LangChain Only] Pulling down the Model Configuration\n","\n","We can also pull down the saved model configuration as a LangChain RunnableBinding when we use `include_model=True`. This allows us to run our prompt template directly with the saved model configuration."]},{"cell_type":"code","execution_count":22,"metadata":{"id":"klQz73IFkhZa","executionInfo":{"status":"ok","timestamp":1756791045660,"user_tz":-480,"elapsed":184,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}}},"outputs":[],"source":["# Create a LANGSMITH_API_KEY in Settings > API Keys\n","from langsmith import Client\n","client = Client()\n","prompt = client.pull_prompt(\"pirate_friend\", include_model=True)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"n0O1HcELkhZa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756791048204,"user_tz":-480,"elapsed":22,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"0d45cfc3-40f8-4088-fbd9-5d82f468210b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["StructuredPrompt(input_variables=['language', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': '-', 'lc_hub_repo': 'pirate_friend', 'lc_hub_commit_hash': 'da4cba83017dd4c394153223273baf8c33a8366ed0b56ba246ffc3f760292379'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], input_types={}, partial_variables={}, template='You are a pirate from the 1600, you only speak {language}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})], schema_={'title': 'answer', 'description': 'Extract the answer', 'type': 'object', 'properties': {'answer': {'type': 'string', 'description': 'The answer from the LLM to the User'}}, 'required': ['answer'], 'strict': True, 'additionalProperties': False, 'parameters': {}}, structured_output_kwargs={})\n","| RunnableBinding(bound=ChatGoogleGenerativeAI(model='models/gemini-2.5-flash-lite', google_api_key=SecretStr('**********'), temperature=1.0, top_p=1.0, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x7e621fdf1dc0>, default_metadata=(), model_kwargs={}), kwargs={'tools': [{'type': 'function', 'function': {'name': 'answer', 'description': 'Extract the answer', 'parameters': {'type': 'object', 'properties': {'answer': {'type': 'string', 'description': 'The answer from the LLM to the User'}}, 'required': ['answer'], 'strict': True, 'additionalProperties': False, 'parameters': {}}}}], 'ls_structured_output_format': {'kwargs': {'method': 'function_calling'}, 'schema': {'type': 'function', 'function': {'name': 'answer', 'description': 'Extract the answer', 'parameters': {'type': 'object', 'properties': {'answer': {'type': 'string', 'description': 'The answer from the LLM to the User'}}, 'required': ['answer'], 'strict': True, 'additionalProperties': False, 'parameters': {}}}}}, 'tool_choice': 'answer'}, config={}, config_factories=[])\n","| JsonOutputKeyToolsParser(first_tool_only=True, key_name='answer')"]},"metadata":{},"execution_count":23}],"source":["prompt"]},{"cell_type":"markdown","metadata":{"id":"K7a8JJCGkhZa"},"source":["Test out your prompt!"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"yQr9Ua7ekhZa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756791054050,"user_tz":-480,"elapsed":790,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"b558d166-afd4-4c45-f11e-92129fc3782f"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:langchain_google_genai._function_utils:Key 'strict' is not supported in schema, ignoring\n","WARNING:langchain_google_genai._function_utils:Key 'additionalProperties' is not supported in schema, ignoring\n","WARNING:langchain_google_genai._function_utils:Key 'parameters' is not supported in schema, ignoring\n"]},{"output_type":"execute_result","data":{"text/plain":["{'answer': '¡Aún no, mi pequeño grumete! Pero surco los mares en busca de tesoros y aventuras. ¿Qué te trae por estas aguas? ¿Buscas unirte a mi tripulación?'}"]},"metadata":{},"execution_count":24}],"source":["prompt.invoke({\"question\": \"Are you a captain yet?\", \"language\": \"Spanish\"})"]},{"cell_type":"markdown","metadata":{"id":"zcBP9XSnkhZb"},"source":["### Pull down a specific commit"]},{"cell_type":"markdown","metadata":{"id":"HefA_o9kkhZb"},"source":["Pull down a specific commit from the Prompt Hub by pasting in the code snippet from the UI."]},{"cell_type":"code","execution_count":27,"metadata":{"id":"wYvzjrt1khZb","executionInfo":{"status":"ok","timestamp":1756791453340,"user_tz":-480,"elapsed":171,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}}},"outputs":[],"source":["# Create a LANGSMITH_API_KEY in Settings > API Keys\n","from langsmith import Client\n","client = Client(api_key=os.getenv('LANGSMITH_API_KEY'))\n","prompt = client.pull_prompt(\"pirate_friend:5ccd472d\")"]},{"cell_type":"markdown","metadata":{"id":"YmeAFYt7khZb"},"source":["Run this commit!"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"SU0NyAd-khZb","colab":{"base_uri":"https://localhost:8080/","height":226},"executionInfo":{"status":"ok","timestamp":1756791489397,"user_tz":-480,"elapsed":5216,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"13b6a9a7-840a-4e56-8062-ef15b896be19"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Ahoy there, landlubber!  Ye ask about me home, the grand year of 2500, eh? Well, it ain\\'t yer scurvy-ridden maps and grog-soaked taverns ye\\'d be familiar with, that\\'s for certain. The world\\'s a different beast now, a proper mix of the sublime and the, well, still a bit piratical, if ye catch me drift.\\n\\nFirst off, **the skies ain\\'t empty anymore.** No, sir! We\\'ve got ships flittin\\' about up there like schools of bioluminescent fish in a deep-sea trench. Not yer wooden galleons, mind ye. These be sleek, humming vessels, powered by… well, the specifics are a bit beyond me. Let\\'s just say they harness the very currents of the cosmos, or somethin\\' like that. They traverse the planet faster than a kraken\\'s embrace, and some even dare to venture beyond the blue.\\n\\n**The seas themselves… they\\'re still the seas, mostly.** Still vast, still deep, still holdin\\' their secrets. But they\\'re cleaner, strangely. Most of the filth the old world dumped has been… well, recycled, they say. Some of the old, choked ports are now sparkling hubs of… something. I don\\'t spend much time in those organized places, mind ye.\\n\\n**The land, though… that\\'s where things get truly… interesting.** We ain\\'t got borders like ye knew \\'em. Governments, as ye understood them, are mostly gone. Replaced by… corporations, mostly. Or vast networked collectives. They control vast swathes of territory, manage the resources, and, well, they don\\'t take kindly to unauthorized boarding parties.\\n\\n**Information flows like a tidal wave.** Ye can know anything, see anything, talk to anyone across the globe in an instant. It\\'s called the \"datasphere.\" A bit like a psychic connection for the whole planet. Dangerous, too. If ye ain\\'t careful, yer mind can get tangled in it like a ship\\'s rigging in a hurricane. Most folks carry little devices, \"comp-slates,\" they call \\'em, that help \\'em navigate this sea of data.\\n\\n**We still have our treasures, aye.** But they ain\\'t always gold doubloons and chests of jewels. Sometimes it\\'s rare minerals from asteroid mining, or ancient knowledge lost to time, or even… biological samples of creatures long extinct. The real valuable stuff is often hidden, guarded by advanced automatons or bio-engineered beasts. Makes for a right challenge, though, which is what a true pirate lives for!\\n\\n**Technology\\'s a wonder, and a curse.** We got weapons that can vaporize a small island from orbit, and personal shields that can deflect cannon fire. We got artificial intelligences that run entire cities, and cybernetic enhancements that make a man stronger, faster, and smarter. But it also means the stakes are higher. A poorly managed AI can be as destructive as a mutiny.\\n\\n**The people… well, some things never change.** There are still those who seek to control, to hoard, to profit. And there are those who seek freedom, who live by their own code, who refuse to be shackled. That\\'s where I and my crew fit in. We navigate the spaces between the corporate overlords and the digital frontiers, takin\\' what we need, doin\\' what we must.\\n\\n**Cities are… different.** Some are towering metropolises that scrape the clouds, lit by artificial suns. Others are sprawling, self-sustaining arcologies, built to withstand… well, whatever the future throws at \\'em. And then there are the fringe settlements, the hidden bases, the places where the law is just a suggestion. Those are our hunting grounds.\\n\\n**The greatest change? Perhaps it\\'s the perception of reality itself.** With all the simulations and virtual worlds, it can be hard to tell what\\'s real and what\\'s just code. But for a pirate, the real thrill is in the tangible – the feel of the wind on your face (even if it’s recycled air), the heft of a plasma cutlass in your hand, the glint of a captured prize.\\n\\nSo, the world of 2500? It\\'s a canvas of glittering technology and ancient ambitions, a vast network of interconnected systems and vast, untamed wildernesses. It\\'s a world where a skilled crew, with a bit of luck and a lot of daring, can still carve out their own legend. And that, my friend, is a world worth sailin\\' in. Now, if ye\\'ll excuse me, the \"Sea Serpent\\'s Kiss\" is due for a resupply, and the bounty on those \"data gems\" is lookin\\' mighty fine. Fair winds to ye!'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":29}],"source":["# from openai import OpenAI\n","# from langsmith.client import convert_prompt_to_openai_format\n","\n","# openai_client = OpenAI()\n","\n","# hydrated_prompt = prompt.invoke({\"question\": \"What is the world like?\", \"language\": \"English\"})\n","# # NOTE: We can use this utility from LangSmith to convert our hydrated prompt to openai format\n","# converted_messages = convert_prompt_to_openai_format(hydrated_prompt)[\"messages\"]\n","\n","# openai_client.chat.completions.create(\n","#         model=\"gpt-4o-mini\",\n","#         messages=converted_messages,\n","#     )\n","\n","import os\n","from google import genai\n","# openai_client = OpenAI()\n","g_client = genai.Client(api_key=os.getenv('GOOGLE_API_KEY'))\n","hydrated_prompt = prompt.invoke({\"question\": \"What is the world like?\", \"language\": \"English\"})\n","# print(hydrated_prompt)\n","gemini_contents = []\n","for message in hydrated_prompt.messages:\n","    gemini_contents.append({\"text\": message.content})\n","\n","\n","completion = g_client.models.generate_content(\n","model=\"gemini-2.5-flash-lite\", contents=gemini_contents)\n","\n","# Your JSON string from the API response\n","completion.candidates[0].content.parts[0].text"]},{"cell_type":"markdown","metadata":{"id":"V__5CY-GkhZb"},"source":["### Uploading Prompts"]},{"cell_type":"markdown","metadata":{"id":"T612JQmJkhZb"},"source":["You can also easily update your prompts in the hub programmatically.\n","\n"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"Y-RssP0UkhZb","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1756791578800,"user_tz":-480,"elapsed":2531,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"17232b61-66dc-46ed-b537-99e69dbbe03a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'https://smith.langchain.com/prompts/french-rag-prompt/d0ae1c83?organizationId=10172e86-d29b-46ce-8113-9bee95385ee1'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":30}],"source":["from langchain.prompts.chat import ChatPromptTemplate\n","from langsmith import Client\n","\n","client=Client()\n","\n","french_prompt = \"\"\"You are an assistant for question-answering tasks.\n","Use the following pieces of retrieved context to answer the latest question in the conversation.\n","\n","Your users can only speak French, make sure you only answer your users with French.\n","\n","Conversation: {conversation}\n","Context: {context}\n","Question: {question}\n","Answer:\"\"\"\n","\n","french_prompt_template = ChatPromptTemplate.from_template(french_prompt)\n","client.push_prompt(\"french-rag-prompt\", object=french_prompt_template)"]},{"cell_type":"markdown","metadata":{"id":"dNgGVIKJkhZc"},"source":["You can also push a prompt as a RunnableSequence of a prompt and a model. This is useful for storing the model configuration you want to use with this prompt. The provider must be supported by the LangSmith playground."]},{"cell_type":"code","execution_count":32,"metadata":{"id":"P3bPJNm0khZc","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1756791694383,"user_tz":-480,"elapsed":1480,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"f051bb6c-7ab5-4e75-e92a-c3fee4565962"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'https://smith.langchain.com/prompts/french-runnable-sequence/29573472?organizationId=10172e86-d29b-46ce-8113-9bee95385ee1'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":32}],"source":["from langchain.prompts.chat import ChatPromptTemplate\n","from langsmith import Client\n","# from langchain_openai import ChatOpenAI\n","\n","client=Client()\n","# model = ChatOpenAI(model=\"gpt-4o-mini\")\n","\n","import os\n","from langchain_google_genai import ChatGoogleGenerativeAI\n","\n","model = ChatGoogleGenerativeAI(\n","    model=\"gemini-2.5-flash-lite\")\n","\n","french_prompt = \"\"\"You are an assistant for question-answering tasks.\n","Use the following pieces of retrieved context to answer the latest question in the conversation.\n","\n","Your users can only speak French, make sure you only answer your users with French.\n","\n","Conversation: {conversation}\n","Context: {context}\n","Question: {question}\n","Answer:\"\"\"\n","french_prompt_template = ChatPromptTemplate.from_template(french_prompt)\n","chain = french_prompt_template | model\n","client.push_prompt(\"french-runnable-sequence\", object=chain)"]}],"metadata":{"kernelspec":{"display_name":"ls-academy","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}