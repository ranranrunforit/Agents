{"cells":[{"cell_type":"markdown","metadata":{"id":"GVZRA17RBvAf"},"source":["# Conversational Threads"]},{"cell_type":"markdown","metadata":{"id":"izAyAQFSBvAg"},"source":["Many LLM applications have a chatbot-like interface in which the user and the LLM application engage in a multi-turn conversation. In order to track these conversations, you can use the Threads feature in LangSmith.\n","\n","This is relevant to our RAG application, which should maintain context from prior conversations with users."]},{"cell_type":"markdown","metadata":{"id":"1Z75zWcgBvAi"},"source":["### Setup"]},{"cell_type":"code","source":["### Mount Notebook to Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","# change the working directory to the Drive root\n","%cd /content/drive/My\\ Drive/Colab\\ Notebooks/intro-to-langsmith-main/notebooks/module_1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MrG5vvjFGgOG","executionInfo":{"status":"ok","timestamp":1756702271133,"user_tz":-480,"elapsed":49581,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"fc7630b1-6c98-486f-8f58-da77b7ddf20c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/My Drive/Colab Notebooks/intro-to-langsmith-main/notebooks/module_1\n"]}]},{"cell_type":"code","source":["!pip install --quiet -U langchain-google-genai langgraph langgraph-sdk langgraph-checkpoint-sqlite langsmith langchain-community langchain-core\n","!pip install --quiet notebook python-dotenv lxml scikit-learn pandas pyarrow"],"metadata":{"id":"pOIAnY-oGxnX","executionInfo":{"status":"ok","timestamp":1756702307115,"user_tz":-480,"elapsed":33425,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"25da8432-465f-4278-b485-ce1f82a451ae"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m378.5/378.5 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.0/444.0 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.6/151.6 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n","google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["!pip install --quiet python-dotenv"],"metadata":{"id":"n9k9ZKUaHA5l","executionInfo":{"status":"ok","timestamp":1756702320284,"user_tz":-480,"elapsed":13185,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from dotenv import load_dotenv\n","load_dotenv(\".env\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nB4-CZXlHAbB","executionInfo":{"status":"ok","timestamp":1756702320776,"user_tz":-480,"elapsed":497,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"b226bba8-fd33-4291-afa4-8be473edf393"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tI0hXwZBBvAj"},"outputs":[],"source":["# You can set them inline\n","import os\n","os.environ[\"OPENAI_API_KEY\"] = \"\"\n","os.environ[\"LANGSMITH_API_KEY\"] = \"\"\n","os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n","os.environ[\"LANGSMITH_PROJECT\"] = \"langsmith-academy\"  # If you don't set this, traces will go to the Default project"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pK10ZuybBvAk"},"outputs":[],"source":["# Or you can use a .env file\n","from dotenv import load_dotenv\n","load_dotenv(dotenv_path=\"../../.env\", override=True)"]},{"cell_type":"markdown","metadata":{"id":"TLeUljJ0BvAk"},"source":["### Group traces into threads\n"]},{"cell_type":"markdown","metadata":{"id":"IIyOZHW-BvAl"},"source":["A Thread is a sequence of traces representing a single conversation. Each response is represented as its own trace, but these traces are linked together by being part of the same thread.\n","\n","To associate traces together, you need to pass in a special metadata key where the value is the unique identifier for that thread.\n","\n","The key value is the unique identifier for that conversation. The key name should be one of:\n","\n","- session_id\n","- thread_id\n","- conversation_id.\n","\n","The value should be a UUID."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"59Ffr5u5BvAm","executionInfo":{"status":"ok","timestamp":1756702325631,"user_tz":-480,"elapsed":16,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}}},"outputs":[],"source":["import uuid\n","thread_id = uuid.uuid4()"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":615,"referenced_widgets":["dddb41d836f24b3096006cf35d3e95c2","8e2b2255147d405a89af9f02930e94ce","6539bf45b86642d095b90a912b0e70db","88b9c96142e24d838ed5edc8e3290137","3c857fc635d0424f99077246b6accfc5","3d615d841c994ec9b3ad182feb8514b6","d56b76a78dbb482db52f418082f495bb","7fed0935701740dab7701cf452776983","b7bcec02fbc24e9d83ce3b024dd90188","5d94d408d8f54f5d9a41cf742b49043d","25133dfde99846d7b68462d30bd49738","5e938785ae8d4279afcd6b071fe9b36e","ea4af1a8eb4a4224962da577dea159bd","a7d664c7b8c74bd9ab6262714bf484af","3e01aea840a54b589246602a50740dad","b17653dc81d04b438718dfe45d556a4e","1f913b0a909d47c8846f83ecd4fd27eb","520d2239495d484d96a4a7d112d23de9","7b5d1b623f6f4d0a80f9b4ce1c0f8384","e18b3c7e2fd24724a1a269419fe89c38","ec5a7595d5ec42fbbc4e88757ad52551","9e4dd349ede64fab9f9b48afe9201b40","f482b727ac934b6099fbf66ddfdef785","7c49a82ea3374cc187b114b3960037f8","c8282a7e006b4cdfaadc98fa7615b673","382ba5616c714043a34f097e0cdfb2e2","63efa029854345d187fa563066bb0407","5ee77f06789f4fdc8f12b09a48f76aa0","9a8d32b7d6fe43ecb78c3cc4d6e26f73","037edbde4be840c4b96b6e03d25b0732","790e3f349a7a45b1bf7ff2a2ff4d2e1f","fb283e68ec3040758bef101bbd65a1b4","440f836577964bbdbaee55941acdc925","4be3a1e836ea4defa9e2c426469b286f","80ba7f68786a473fb2d9bad2a72359c4","a131517b1d3d4ddeb53357462eb28ca0","ad7213f6d51a403a834214ec1be29919","62f94d2b3dca4362860f27820b6f306d","d525714058964162af31c6d78f2693d5","cc33f3465a484f2b991746c2356728d1","c218fc5d127c491f8719609991fd53bf","a05d090cb0fe4aa6b6f85a2adc5fb23f","1392c79826854fddb14ae5c37fdb0f5a","dc5f962469fa4eddb94c34c8d29233fb","ddf7c175d45b4ac4837e5c622494dfc7","495dabfb723d407694228aa346fcd146","aa564fb30919414bbf701c9b2f4c14ed","a7ef05077a1742ab8dee983630ef8ea7","31a0d282c47447d88a1180942fbcf5b0","56bf529c25134586a3ff85fc2d6f4fdf","46c6c64bbaca4985952852f3ee7b6460","9d3f966daf8f433ba512c858336e30cd","749a9da3c6a9487c8c4c50f08e67ab26","c8420d73106e4801b992384acf019a4d","eff1eab4dc8b4caeb1b7e383ac36131f","ad20085b3c6548d9b55928bbf9ff1cca","0e5bba248ea24ce0a5bb857fbf2c89c8","580d508f97ad4177b864d9aa08130d1a","818dfc53784e47ff9f9b626a9455240d","9e1527bb59e14845b47ee75e04105abf","281e2a004bea476294ad7a818df9b369","4e3c7cdc62114612988243f5d9c6ca54","a197e4f7a8f547b68ce6b1e0f2a2d2de","7386a00709674b8d82ef51a094688713","6bce6c5a11c1450b8cede7df043280a3","1ed8191a9235437eb309d61ecf319f70","a90bfa93191c429aa17db01d2f36e2aa","f19745a74bff4be0ab59b903fb9fa753","a1955000078a4ae0a601b779c5e0dbb5","f909af5ccfdb46bd8f247ed406b0a293","5340dfd56f834ed1a024432884508cf9","709455456fb746a5bf71c1314263b71b","50e5c95fe1e64aaeb4612dc351bd82a1","2c20022a0d5b481ea672cada6b6f2425","b53303af9aac4184a71dafac418297d1","b0480b001f854501a72b34aecf41c1b2","eec377e9b834495b9f3afd17a3ef4b2d","e414aae3d7b340569f7fee87275168cc","5f02415a40d24bae90dd9e81e53f24e2","b2b95d03c9204ee4b3fd47177f9405a7","ae8feb37adfe40f4997010856154c87e","2f0413e0d3804fa080f56ea0830576d5","fab90ab00e244326b3764b3f0b020c39","4175b94700d34f0eb1bd8b47ab8e97a3","b293aa77fdf64a69b262566ff5a24c7a","bba2a1526b764656a84ae8fbe179dae9","62df87a8ca7c45d4bb90a2166f76a061","00a1ae4c504647deb1bd671af6f64445","2c8a7df05dce4ebfab26a49040cc529c","10848f2aef324c0e945be29df0fbe63d","e918dc904416413290353a2048a84330","774b42f7b67e4a14851f0f2402280c93","ff2e4887593d4337a911d2c16c1afe81","164627f05e3c487fb374bd940f3662bf","bffb0a4a73e948988b1ccd50db88bbe7","fd5410e85534494ca4550a93a7bf2daa","d3fe33e62f4d450da84789aeaa002d05","f4e237a477484f4d9fa997ec18053f88","e112475a6ef4492a9aa84ba9bd3ddf25","46ba4d1e602446cca490294c37b5e502","e903cf366e424d2c92d478f490d50fd4","db4bb44df16a4286acf44859eae2c4d5","65da0d6b8c154016a52962de2c3ea110","a1ad2f4c1c654fe994559bb3433b10c3","569c60d601934118a9db243ec10f63a6","049e341bcc72434a82dd162008cb3d7b","a390950b633f48deb932474493d166e2","0c783fdf3a854b1c81d39f040dd0b7b8","8a0530161e79440daefe38f04e46721d","c7ea056fd7954287b3fd2437a31325ad","917ec5a3d7d24a069e0464c2711c74a2","603092e3b7584dcab8977e856c152a74","347725f123654b2ea649467cb990654a","d7c2fd26cfc0420ca429f76c59879071","d48eace85b5548aab70fc78efb89b451","6ef272bcc8a94b25a24c372b2d6612b9","9ba01a25cf324f18afe543dc6c659038","671a6fccbf714ce69eba7d8b248791b8","58fdc9913c3047179808d5257b08f9a0","6458833bf4184ad985b9ab4884db459c","8427c6131e17462fbfc0377796cea40c"]},"id":"dkUUg9T0BvAn","executionInfo":{"status":"ok","timestamp":1756702543224,"user_tz":-480,"elapsed":211092,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"75f7d997-7a22-4da9-9992-f807b25834f1"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n","/content/drive/MyDrive/Colab Notebooks/intro-to-langsmith-main/notebooks/module_1/utils.py:37: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n","  embd = HuggingFaceEmbeddings(\n","/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dddb41d836f24b3096006cf35d3e95c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e938785ae8d4279afcd6b071fe9b36e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["README.md: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f482b727ac934b6099fbf66ddfdef785"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4be3a1e836ea4defa9e2c426469b286f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ddf7c175d45b4ac4837e5c622494dfc7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad20085b3c6548d9b55928bbf9ff1cca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a90bfa93191c429aa17db01d2f36e2aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e414aae3d7b340569f7fee87275168cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c8a7df05dce4ebfab26a49040cc529c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46ba4d1e602446cca490294c37b5e502"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"917ec5a3d7d24a069e0464c2711c74a2"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["No existing vector store found. Indexing documents...\n"]},{"output_type":"stream","name":"stderr","text":["Fetching pages: 100%|##########| 197/197 [00:21<00:00,  9.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Created 1174 document splits. Creating vector store...\n","Persisting vector store to: /tmp/union_local.parquet\n"]}],"source":["from langsmith import traceable\n","# from openai import OpenAI\n","from typing import List\n","import nest_asyncio\n","from utils import get_vector_db_retriever\n","\n","import os\n","from google import genai\n","# openai_client = OpenAI()\n","client = genai.Client(api_key=os.getenv('GOOGLE_API_KEY'))\n","nest_asyncio.apply()\n","retriever = get_vector_db_retriever()\n","\n","@traceable(run_type=\"chain\")\n","def retrieve_documents(question: str):\n","    return retriever.invoke(question)\n","\n","@traceable(run_type=\"chain\")\n","def generate_response(question: str, documents):\n","    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\n","    rag_system_prompt = \"\"\"You are an assistant for question-answering tasks.\n","    Use the following pieces of retrieved context to answer the latest question in the conversation.\n","    If you don't know the answer, just say that you don't know.\n","    Use three sentences maximum and keep the answer concise.\n","    \"\"\"\n","    # messages = [\n","    #     {\n","    #         \"role\": \"system\",\n","    #         \"content\": rag_system_prompt\n","    #     },\n","    #     {\n","    #         \"role\": \"user\",\n","    #         \"content\": f\"Context: {formatted_docs} \\n\\n Question: {question}\"\n","    #     }\n","    # ]\n","    messages = [\n","                  {\n","                      \"role\": \"user\",\n","                      \"parts\": [\n","                          {\"text\": rag_system_prompt},\n","                          {\"text\": f\"Context: {formatted_docs} \\n\\n Question: {question}\"}\n","                      ]\n","                  }\n","              ]\n","    return call_gemini(messages)\n","\n","@traceable(run_type=\"llm\")\n","def call_gemini(\n","    messages: List[dict], model: str = \"gemini-2.5-flash\", temperature: float = 0.0\n",") -> str:\n","    # return openai_client.chat.completions.create(\n","    #     model=model,\n","    #     messages=messages,\n","    #     temperature=temperature,\n","    # )\n","    return client.models.generate_content(\n","    model=model, contents=messages\n","    )\n","\n","@traceable(run_type=\"chain\")\n","def langsmith_rag(question: str):\n","    documents = retrieve_documents(question)\n","    response = generate_response(question, documents)\n","    # return response.choices[0].message.content\n","    return response.candidates[0].content.parts[0].text"]},{"cell_type":"markdown","metadata":{"id":"UQnXuQiSBvAo"},"source":["### Now let's run our application twice with this thread_id"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aND34dYLBvAp","executionInfo":{"status":"ok","timestamp":1756702605495,"user_tz":-480,"elapsed":2173,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"181b9b34-cba0-4b0a-d4f9-4bde49a85113"},"outputs":[{"output_type":"stream","name":"stdout","text":["You can add metadata to a trace as a dictionary of key-value pairs. This allows you to associate additional information, such as the execution environment or user, with the trace. For instance, you can include metadata using the `@traceable` decorator on a function.\n"]}],"source":["question = \"How do I add metadata to a Trace?\"\n","ai_answer = langsmith_rag(question, langsmith_extra={\"metadata\": {\"thread_id\": thread_id}})\n","print(ai_answer)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NGvljUN9BvAq","executionInfo":{"status":"ok","timestamp":1756702610039,"user_tz":-480,"elapsed":1313,"user":{"displayName":"Chaoran Zhou","userId":"09162553986537566448"}},"outputId":"cc2fa9ec-5612-4454-a248-65bc33cbe81d"},"outputs":[{"output_type":"stream","name":"stdout","text":["You can add tags to a trace in LangSmith, which are collections of strings used to categorize runs. This functionality is supported for both the `traceable` decorator and `RunTree` objects. Tags help associate additional information with a trace and make it easier to search and filter runs in the LangSmith UI.\n"]}],"source":["question = \"How can I add tags to a Trace?\"\n","ai_answer = langsmith_rag(question, langsmith_extra={\"metadata\": {\"thread_id\": thread_id}})\n","print(ai_answer)"]},{"cell_type":"markdown","metadata":{"id":"boD9HyB8BvAr"},"source":["### Let's take a look in LangSmith!"]}],"metadata":{"kernelspec":{"display_name":"ls-academy","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}